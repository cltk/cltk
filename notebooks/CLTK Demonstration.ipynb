{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data\n",
    "\n",
    "The following obtain two plaintext documents of two Classical authors. A subset of each will be used to demonstrate the CLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n"
     ]
    }
   ],
   "source": [
    "# Get Latin text\n",
    "# https://gist.github.com/kylepjohnson/2f9376fcf15699c250a0d09b37683370\n",
    "# now at `notebooks/lat-livy.txt`\n",
    "!curl -O https://gist.github.com/kylepjohnson/2f9376fcf15699c250a0d09b37683370/raw/4b98b15017b1bd31e77447309bd9b7cb9086349c/lat-livy.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n"
     ]
    }
   ],
   "source": [
    "# Get Ancient Greek text\n",
    "# https://gist.github.com/kylepjohnson/9835c36fb06ca30ebf29b7f2c7bd29e0\n",
    "# now at `notebooks/grc-thucydides.txt`\n",
    "!curl -O https://gist.github.com/kylepjohnson/9835c36fb06ca30ebf29b7f2c7bd29e0/raw/8f5aa440363dc66952bb1eb12effc7d3ada101a8/grc-thucydides.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Latin file\n",
    "# We'll run the full demonstration in the Latin language first\n",
    "with open(\"lat-livy.txt\") as fo:\n",
    "    livy_full = fo.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text snippet: riptores aut in rebus certius aliquid allaturos se aut scribendi arte rudem vetustatem superaturos credunt. utcumque erit, iuvabit tamen rerum gestarum memoriae principis terrarum populi pro virili pa\n",
      "Character count: 3580331\n",
      "Approximate token count: 503818\n"
     ]
    }
   ],
   "source": [
    "print(\"Text snippet:\", livy_full[200:400])\n",
    "print(\"Character count:\", len(livy_full))\n",
    "print(\"Approximate token count:\", len(livy_full.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71606"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(livy_full) // 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate token count: 10209\n"
     ]
    }
   ],
   "source": [
    "# Now let's cut this down to roughly 10k tokens for this demonstration's purposes\n",
    "livy = livy_full[:len(livy_full) // 50]\n",
    "print(\"Approximate token count:\", len(livy.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run NLP pipeline with `NLP()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For most users, this is the only import required\n",
    "from cltk import NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the default Pipeline for Latin\n",
    "cltk_nlp = NLP(language=\"lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.8 s, sys: 7.84 s, total: 58.7 s\n",
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "# Now execute NLP algorithms upon input text\n",
    "# Execution time is 54 sec on a 2015 Macbook Pro\n",
    "%time cltk_doc = cltk_nlp.analyze(text=livy)\n",
    "\n",
    "# You will be asked to download some models (from CLTK, fastText, and Stanza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect CLTK `Doc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cltk.core.data_types.Doc'>\n"
     ]
    }
   ],
   "source": [
    "# We can now inspect the result\n",
    "print(type(cltk_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_get_words_attribute', 'embeddings', 'embeddings_model', 'language', 'lemmata', 'morphosyntactic_features', 'pipeline', 'pos', 'raw', 'sentences', 'sentences_strings', 'sentences_tokens', 'stanza_doc', 'stems', 'tokens', 'tokens_stops_filtered', 'words']\n"
     ]
    }
   ],
   "source": [
    "# All accessors\n",
    "print([x for x in dir(cltk_doc) if not x.startswith(\"__\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['facturusne', 'operae', 'pretium', 'sim', ',', 'si', 'a', 'primordio', 'urbis', 'res', 'populi', 'Romani', 'perscripserim', ',', 'nec', 'satis', 'scio', 'nec', ',', 'si']\n"
     ]
    }
   ],
   "source": [
    "# Several of the more useful\n",
    "\n",
    "# List of tokens\n",
    "print(cltk_doc.tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['facturusne', 'opus', 'pretium', 'sum', ',', 'si', 'ab', 'primordius', 'urbis', 'res', 'populus', 'momanum', 'perscribo', ',', 'nec', 'satis', 'scio', 'nec', ',', 'si']\n"
     ]
    }
   ],
   "source": [
    "# List of lemmas\n",
    "print(cltk_doc.lemmata[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADV', 'NOUN', 'NOUN', 'AUX', 'PUNCT', 'SCONJ', 'ADP', 'ADJ', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'PUNCT', 'CCONJ', 'ADV', 'VERB', 'CCONJ', 'PUNCT', 'SCONJ']\n"
     ]
    }
   ],
   "source": [
    "# Basic part-of-speech info\n",
    "print(cltk_doc.pos[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['facturusne', 'operae', 'pretium', 'sim', ',', 'si', 'a', 'primordio', 'urbis', 'res', 'populi', 'Romani', 'perscripserim', ',', 'nec', 'satis', 'scio', 'nec', ',', 'si', 'sciam', ',', 'dicere', 'ausim', ',', 'quippe', 'qui', 'cum', 'veterem', 'tum', 'vulgatam', 'esse', 'rem', 'videam', ',', 'dum', 'novi', 'semper', 'scriptores', 'aut', 'in', 'rebus', 'certius', 'aliquid', 'allaturos', 'se', 'aut', 'scribendi', 'arte', 'rudem', 'vetustatem', 'superaturos', 'credunt', '.'], ['utcumque', 'erit', ',', 'iuvabit', 'tamen', 'rerum', 'gestarum', 'memoriae', 'principis', 'terrarum', 'populi', 'pro', 'virili', 'parte', 'et', 'ipsum', 'consuluisse', ';']]\n"
     ]
    }
   ],
   "source": [
    "# A list of list of tokens\n",
    "print(cltk_doc.sentences_tokens[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect CLTK `Word`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most powerful, though, is the ``Doc.words`` accessor, which is a list of ``Word`` objects. These ``Word`` objects contain all information that was generated during the NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11735\n"
     ]
    }
   ],
   "source": [
    "# One ``Word`` object for each token\n",
    "print(len(cltk_doc.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can go token-by-token via ``Doc.words`` or via the intermediary step of looping through sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Ibi egressi Troiani , ut quibus ab immenso prope errore nihil praeter arma et naues superesset , cum praedam ex agris agerent , Latinus rex Aboriginesque qui tum ea tenebant loca ad arcendam vim advenarum armati ex urbe atque agris concurrunt .\n",
      "\n",
      "Translation: Landing there, the Trojans, as men who, after their all but immeasurable wanderings, had nothing left but their swords and ships, were driving booty from the fields, when King Latinus and the Aborigines, who then occupied that country, rushed down from their city and their fields to repel with arms the violence of the invaders.\n"
     ]
    }
   ],
   "source": [
    "# Let's look at a non-trivial sentence from Book 1\n",
    "print(\"Original:\", cltk_doc.sentences_strings[26])\n",
    "print(\"\")\n",
    "print(\"Translation:\", \"Landing there, the Trojans, as men who, after their all but immeasurable wanderings, had nothing left but their swords and ships, were driving booty from the fields, when King Latinus and the Aborigines, who then occupied that country, rushed down from their city and their fields to repel with arms the violence of the invaders.\")\n",
    "# source: http://www.perseus.tufts.edu/hopper/text?doc=Liv.+1+1+5&fromdoc=Perseus%3Atext%3A1999.02.0151\n",
    "sentence_26 = cltk_doc.sentences[26]  # type: List[Word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word(index_char_start=None, index_char_stop=None, index_token=40, index_sentence=26, string='concurrunt', pos=verb, lemma='concurro', stem=None, scansion=None, xpos='L3|modA|tem1|gen9', upos='VERB', dependency_relation='acl:relcl', governor=33, features={Mood: [indicative], Number: [plural], Person: [third], Tense: [present], VerbForm: [finite], Voice: [active]}, category={F: [neg], N: [neg], V: [pos]}, embedding=array([-0.16746  , -0.18548  ,  0.30632  , -0.29627  , -0.27262  ,\n",
       "       -0.0767   ,  0.19405  ,  0.12386  , -0.0076342,  0.13037  ,\n",
       "        0.17128  ,  0.1189   , -0.22169  , -0.57089  ,  0.28066  ,\n",
       "       -0.14514  , -0.041256 , -0.021754 ,  0.02212  , -0.25983  ,\n",
       "        0.53374  , -0.042267 ,  0.27314  ,  0.083616 ,  0.30746  ,\n",
       "        0.087764 , -0.10098  ,  0.22689  , -0.17577  , -0.35894  ,\n",
       "       -0.39609  ,  0.43406  ,  0.21306  ,  0.26909  ,  0.099561 ,\n",
       "        0.26916  , -0.46547  ,  0.1416   , -0.21319  , -0.15126  ,\n",
       "        0.36604  , -0.020737 ,  0.42397  ,  0.014221 ,  0.14055  ,\n",
       "        0.21519  ,  0.11099  ,  0.03183  , -0.26811  ,  0.2691   ,\n",
       "       -0.059489 , -0.32648  , -0.47286  , -0.054011 ,  0.64627  ,\n",
       "        0.40984  , -0.26108  , -0.006157 ,  0.016047 , -0.36     ,\n",
       "       -0.0059306,  0.036475 , -0.26611  ,  0.22437  , -0.030462 ,\n",
       "        0.27057  , -0.43477  ,  0.39011  ,  0.11665  , -0.17181  ,\n",
       "        0.1938   ,  0.30478  ,  0.15594  , -0.24797  , -0.28985  ,\n",
       "       -0.50473  ,  0.12834  ,  0.13296  ,  0.20974  ,  0.18452  ,\n",
       "       -0.049739 ,  0.30645  , -0.1036   , -0.0051733, -0.37052  ,\n",
       "        0.05242  ,  0.47427  ,  0.11924  ,  0.17432  ,  0.0051695,\n",
       "       -0.19177  ,  0.30655  ,  0.15158  ,  0.44306  ,  0.0094918,\n",
       "        0.066288 ,  0.43126  ,  0.14704  , -0.21296  ,  0.065158 ,\n",
       "       -0.051074 , -0.071807 , -0.30076  ,  0.094454 , -0.01951  ,\n",
       "       -0.30378  ,  0.071281 ,  0.097893 ,  0.1682   ,  0.14394  ,\n",
       "        0.16555  ,  0.18857  , -0.21343  , -0.39882  , -0.0056818,\n",
       "        0.13572  ,  0.4581   ,  0.26051  ,  0.091876 ,  0.15996  ,\n",
       "       -0.15423  , -0.032577 ,  0.3355   ,  0.053628 ,  0.16543  ,\n",
       "        0.12325  ,  0.62661  ,  0.019613 ,  0.25669  , -0.40527  ,\n",
       "        0.17728  ,  0.21147  , -0.15291  , -0.044267 , -0.18761  ,\n",
       "       -0.22989  , -0.15356  , -0.12118  ,  0.4221   ,  0.14455  ,\n",
       "       -0.098447 , -0.0689   ,  0.286    ,  0.057885 , -0.41445  ,\n",
       "        0.2779   , -0.016358 , -0.62472  , -0.14563  ,  0.019347 ,\n",
       "        0.2676   , -0.40895  ,  0.046428 , -0.024668 , -0.07123  ,\n",
       "        0.29799  ,  0.0441   , -0.020152 ,  0.7785   ,  0.066722 ,\n",
       "        0.40216  , -0.065465 ,  0.29178  , -0.045332 , -0.28099  ,\n",
       "        0.12069  ,  0.092256 , -0.28262  ,  0.16332  , -0.11963  ,\n",
       "        0.23084  ,  0.095945 ,  0.26448  , -0.070788 , -0.090602 ,\n",
       "        0.21045  ,  0.10711  ,  0.072995 ,  0.36067  , -0.66715  ,\n",
       "       -0.092171 , -0.17343  , -0.086316 ,  0.064014 , -0.037073 ,\n",
       "        0.19314  , -0.24475  ,  0.36475  ,  0.44256  ,  0.34814  ,\n",
       "       -0.23052  , -0.33464  , -0.25515  , -0.0062384,  0.16953  ,\n",
       "       -0.21684  , -0.50552  , -0.26195  ,  0.18859  , -0.024014 ,\n",
       "        0.16651  ,  0.19608  , -0.014255 ,  0.022351 , -0.15028  ,\n",
       "       -0.27432  , -0.090952 , -0.0053178, -0.17972  , -0.17313  ,\n",
       "       -0.022731 , -0.047864 ,  0.13094  ,  0.48215  ,  0.27521  ,\n",
       "        0.23869  , -0.18862  , -0.33807  , -0.09874  ,  0.18834  ,\n",
       "       -0.15856  , -0.19709  ,  0.091342 ,  0.18845  ,  0.24375  ,\n",
       "       -0.071029 ,  0.25485  , -0.20413  , -0.12763  ,  0.034578 ,\n",
       "       -0.098762 ,  0.29447  , -0.2311   , -0.26438  ,  0.53568  ,\n",
       "       -0.024871 , -0.081562 , -0.20891  , -0.31516  , -0.041829 ,\n",
       "        0.22537  ,  0.17958  ,  0.21367  ,  0.020792 , -0.17514  ,\n",
       "        0.12402  ,  0.17977  ,  0.093449 ,  0.21696  ,  0.027229 ,\n",
       "        0.065418 , -0.15782  , -0.2414   ,  0.18637  , -0.12432  ,\n",
       "        0.10779  ,  0.13641  ,  0.025108 ,  0.19791  ,  0.0093455,\n",
       "        0.36186  ,  0.25091  ,  0.13112  ,  0.18152  ,  0.021867 ,\n",
       "        0.11931  , -0.4036   , -0.27416  , -0.38616  , -0.28777  ,\n",
       "       -0.086809 , -0.43366  , -0.091819 ,  0.21763  , -0.13074  ,\n",
       "        0.20796  ,  0.31517  , -0.020933 ,  0.058451 , -0.33536  ,\n",
       "        0.59479  , -0.10157  , -0.17879  , -0.28129  ,  0.14399  ,\n",
       "        0.45861  , -0.030208 , -0.2507   , -0.27942  ,  0.26798  ,\n",
       "       -0.49253  , -0.18972  , -0.044783 ,  0.2852   , -0.046358 ,\n",
       "        0.33655  ,  0.012819 , -0.059189 , -0.1022   , -0.16723  ],\n",
       "      dtype=float32), stop=False, named_entity=False, syllables=None, phonetic_transcription=None)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at one Word, 'concurrunt' ('they run together')\n",
    "sentence_26[40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this word, you can see information for lexicography (`.lemmata`), semantics (`.embedding`), morphology (`.pos`, `.features`), syntax (`.governor`, `.dependency_relation`), plus other information most users would find helpful (`.stop`, `.named_entity`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling morphology\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling syntax\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    "The following give some examples of helpers which assist in preparing `Doc` information for machine learning.\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatinPipeline(description='Pipeline for the Latin language', processes=[<class 'cltk.dependency.processes.LatinStanzaProcess'>, <class 'cltk.embeddings.processes.LatinEmbeddingsProcess'>, <class 'cltk.stops.processes.StopsProcess'>, <class 'cltk.ner.processes.LatinNERProcess'>], language=Language(name='Latin', glottolog_id='lati1261', latitude=41.9026, longitude=12.4502, dates=[], family_id='indo1319', parent_id='impe1234', level='language', iso_639_3_code='lat', type='a'))\n"
     ]
    }
   ],
   "source": [
    "# View default processes\n",
    "print(cltk_nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[(i, s) for i, s in enumerate(cltk_doc.sentences_strings[:100])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

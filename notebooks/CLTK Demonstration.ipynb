{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Introduction](#introduction)\n",
    "1. [Install pre-release of CLTK](#install)\n",
    "1. [Get data](#get-data)\n",
    "1. [Run NLP pipeline with `NLP()`](#run-nlp)\n",
    "1. [Inspect CLTK `Doc`](#inspect-doc)\n",
    "1. [Inspect CLTK `Word`](#inspect-word)\n",
    "1. [Modeling morphology with `MorphosyntacticFeature` and `MorphosyntacticFeatureBundle`](#morph)\n",
    "1. [Modeling syntax with `Form` and `DependencyTree`](#syntax)\n",
    "1. [Feature extraction](#features)\n",
    "1. [Brief demonstration of `NLP()` for Ancient Greek](#greek-nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "This notebook demonstrates how to use `NLP()`, the CLTK's primary interface, in Latin and Ancient Greek. Pipelines are available for 17 languages (see [Languages](https://docs.cltk.org/en/latest/languages.html) in the docs).\n",
    "\n",
    "Full documentation available at <https://docs.cltk.org/en/latest/cltk.html#cltk.nlp.NLP>.\n",
    "\n",
    "Note that there is a large amoung of code from this project's first six years (v. `0.1`), not all of which has been or will be moved over to this v. `1.0`. Docs for `0.1` still available at [https://legacy.cltk.org](https://legacy.cltk.org/) and tutorial notebooks at [https://github.com/cltk/tutorials](https://github.com/cltk/tutorials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install CLTK <a name=\"install\"></a>\n",
    "\n",
    "This notebook comes from <https://github.com/cltk/cltk/tree/master/notebooks>. For full instructions on installing the CLTK are available at <https://docs.cltk.org/en/latest/installation.html>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Or directly from this repo:\n",
    "# cd .. && make install\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data <a name=\"get-data\"></a>\n",
    "\n",
    "The following obtain two plaintext documents of two Classical authors. A subset of each will be used to demonstrate the CLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Latin text\n",
    "# https://gist.github.com/kylepjohnson/2f9376fcf15699c250a0d09b37683370\n",
    "# now at `notebooks/lat-livy.txt`\n",
    "# !curl -O -L https://gist.github.com/kylepjohnson/2f9376fcf15699c250a0d09b37683370/raw/05b7a17af4b216a4986d897c57a9987e836cc91a/lat-livy.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Ancient Greek text\n",
    "# https://gist.github.com/kylepjohnson/9835c36fb06ca30ebf29b7f2c7bd29e0\n",
    "# now at `notebooks/grc-thucydides.txt`\n",
    "# !curl -O -L https://gist.github.com/kylepjohnson/9835c36fb06ca30ebf29b7f2c7bd29e0/raw/e08e47849f64484b0950b14563bb5a9fd1e1ef1c/grc-thucydides.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Latin file\n",
    "# We'll run the full demonstration in the Latin language first\n",
    "with open(\"lat-livy.txt\") as fo:\n",
    "    livy_full = fo.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text snippet: Iam primum omnium satis constat Troia capta in ceteros saevitum esse Troianos, duobus, Aeneae Antenorique, et vetusti iure hospitii et quia pacis reddendaeque Helenae semper auctores fuerant, omne ius\n",
      "Character count: 920884\n",
      "Approximate token count: 129799\n"
     ]
    }
   ],
   "source": [
    "print(\"Text snippet:\", livy_full[:200])\n",
    "print(\"Character count:\", len(livy_full))\n",
    "print(\"Approximate token count:\", len(livy_full.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76740"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(livy_full) // 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate token count: 10911\n"
     ]
    }
   ],
   "source": [
    "# Now let's cut this down to roughly 10k tokens for this demonstration's purposes\n",
    "livy = livy_full[:len(livy_full) // 12]\n",
    "print(\"Approximate token count:\", len(livy.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run NLP pipeline with `NLP()` <a name=\"run-nlp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For most users, this is the only import required\n",
    "from cltk import NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äéê§Ä CLTK version '1.1.7'.\n",
      "Pipeline for language 'Latin' (ISO: 'lat'): `LatinNormalizeProcess`, `LatinSpacyProcess`, `LatinLexiconProcess`.\n"
     ]
    }
   ],
   "source": [
    "# Load the default Pipeline for Latin\n",
    "cltk_nlp = NLP(language=\"lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'cltk.alphabet.processes.LatinNormalizeProcess'>, <class 'cltk.dependency.processes.LatinSpacyProcess'>]\n"
     ]
    }
   ],
   "source": [
    "# Removing ``LatinLexiconProcess`` for this demo b/c it is slow (adds ~9 mins total)\n",
    "cltk_nlp.pipeline.processes.pop(-1)\n",
    "print(cltk_nlp.pipeline.processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.27 s, sys: 604 ms, total: 4.88 s\n",
      "Wall time: 4.91 s\n"
     ]
    }
   ],
   "source": [
    "# Now execute NLP algorithms upon input text\n",
    "# Aside from download, execution time is ~50 sec on a 2015 Macbook Pro\n",
    "%time cltk_doc = cltk_nlp.analyze(text=livy)\n",
    "\n",
    "# You will be asked to download some models (from CLTK, fastText, and Stanza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect CLTK `Doc` <a name=\"inspect-doc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cltk.core.data_types.Doc'>\n"
     ]
    }
   ],
   "source": [
    "# We can now inspect the result\n",
    "print(type(cltk_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_get_words_attribute', 'embeddings', 'embeddings_model', 'language', 'lemmata', 'morphosyntactic_features', 'normalized_text', 'pipeline', 'pos', 'raw', 'sentence_embeddings', 'sentences', 'sentences_strings', 'sentences_tokens', 'spacy_doc', 'stems', 'tokens', 'tokens_stops_filtered', 'words']\n"
     ]
    }
   ],
   "source": [
    "# All accessors\n",
    "print([x for x in dir(cltk_doc) if not x.startswith(\"__\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iam', 'primum', 'omnium', 'satis', 'constat', 'Troia', 'capta', 'in', 'ceteros', 'saevitum', 'esse', 'Troianos', ',', 'duobus', ',', 'Aeneae', 'Antenori', 'que', ',', 'et']\n"
     ]
    }
   ],
   "source": [
    "# Several of the more useful\n",
    "\n",
    "# List of tokens\n",
    "print(cltk_doc.tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iam', 'primum', 'omnis', 'satis', 'consto', 'Troia', 'campo', 'in', 'ceterus', 'saevitum', 'sum', 'Troianos', ',', 'duo', ',', 'aeneae', 'Antenor', 'que', ',', 'et']\n"
     ]
    }
   ],
   "source": [
    "# List of lemmas\n",
    "print(cltk_doc.lemmata[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADV', 'ADJ', 'ADJ', 'ADV', 'VERB', 'NOUN', 'VERB', 'ADP', 'ADJ', 'VERB', 'AUX', 'ADJ', 'PUNCT', 'NUM', 'PUNCT', 'PROPN', 'PROPN', 'NOUN', 'PUNCT', 'CCONJ']\n"
     ]
    }
   ],
   "source": [
    "# Basic part-of-speech info\n",
    "print(cltk_doc.pos[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Iam', 'primum', 'omnium', 'satis', 'constat', 'Troia', 'capta', 'in', 'ceteros', 'saevitum', 'esse', 'Troianos', ',', 'duobus', ',', 'Aeneae', 'Antenori', 'que', ',', 'et', 'vetusti', 'iure', 'hospitii', 'et', 'quia', 'pacis', 'reddendae', 'que', 'Helenae', 'semper', 'auctores', 'fuerant', ',', 'omne', 'ius', 'belli', 'Achiuos', 'abstinuisse', ';'], ['casibus', 'deinde', 'variis', 'Antenorem', 'cum', 'multitudine', 'Enetum', ',', 'qui', 'seditione', 'ex', 'Paphlagonia', 'pulsi', 'et', 'sedes', 'et', 'ducem', 'rege', 'Pylaemene', 'ad', 'Troiam', 'amisso', 'quaerebant', ',', 'venisse', 'in', 'intimum', 'maris', 'Hadriatici', 'sinum', ',', 'Euganeis', 'que', 'qui', 'inter', 'mare', 'Alpes', 'que', 'incolebant', 'pulsis', 'Enetos', 'Troianos', 'que', 'eas', 'tenuisse', 'terras', '.']]\n"
     ]
    }
   ],
   "source": [
    "# A list of list of tokens\n",
    "print(cltk_doc.sentences_tokens[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect CLTK `Word` <a name=\"inspect-word\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most powerful, though, is the ``Doc.words`` accessor, which is a list of ``Word`` objects. These ``Word`` objects contain all information that was generated during the NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12986\n"
     ]
    }
   ],
   "source": [
    "# One ``Word`` object for each token\n",
    "print(len(cltk_doc.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can go token-by-token via ``Doc.words`` or via the intermediary step of looping through sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Ibi egressi Troiani , ut quibus ab immenso prope errore nihil praeter arma et naues superesset , cum praedam ex agris agerent , Latinus rex Aborigines que qui tum ea tenebant loca ad arcendam vim advenarum armati ex urbe atque agris concurrunt .\n",
      "\n",
      "Translation: Landing there, the Trojans, as men who, after their all but immeasurable wanderings, had nothing left but their swords and ships, were driving booty from the fields, when King Latinus and the Aborigines, who then occupied that country, rushed down from their city and their fields to repel with arms the violence of the invaders.\n"
     ]
    }
   ],
   "source": [
    "# Let's look at a non-trivial sentence from Book 1\n",
    "print(\"Original:\", cltk_doc.sentences_strings[5])\n",
    "print(\"\")\n",
    "print(\"Translation:\", \"Landing there, the Trojans, as men who, after their all but immeasurable wanderings, had nothing left but their swords and ships, were driving booty from the fields, when King Latinus and the Aborigines, who then occupied that country, rushed down from their city and their fields to repel with arms the violence of the invaders.\")\n",
    "# source: http://www.perseus.tufts.edu/hopper/text?doc=Liv.+1+1+5&fromdoc=Perseus%3Atext%3A1999.02.0151\n",
    "sentence_6 = cltk_doc.sentences[5]  # type: List[Word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word(index_char_start=1091, index_char_stop=1101, index_token=188, index_sentence=5, string='concurrunt', pos=verb, lemma='concurro', stem=None, scansion=None, xpos='verb', upos='VERB', dependency_relation='conj', governor=162, features={Mood: [indicative], Number: [plural], Person: [third], Tense: [present], VerbForm: [finite], Voice: [active]}, category={F: [neg], N: [neg], V: [pos]}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n"
     ]
    }
   ],
   "source": [
    "# Looking at one Word, 'concurrunt' ('they run together')\n",
    "a_word_concurrunt = sentence_6[41]\n",
    "print(a_word_concurrunt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this word, you can see information for lexicography (`.lemmata`), semantics (`.embedding`), morphology (`.pos`, `.features`), syntax (`.governor`, `.dependency_relation`), plus other information most users would find helpful (`.stop`, `.named_entity`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling morphology with `MorphosyntacticFeature` and `MorphosyntacticFeatureBundle` <a name=\"morph\"></a>\n",
    "\n",
    "When a language's `Pipeline` builds each `Word` object, morphological information is stored at several accessors. Those of interest to most users are `.pos` and `.features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Word.string`: concurrunt\n",
      "\n",
      "`Word.pos`: verb\n"
     ]
    }
   ],
   "source": [
    "print(\"`Word.string`:\", a_word_concurrunt.string)\n",
    "print(\"\")\n",
    "# Part-of-speech is always be available at `.pos`.\n",
    "print(\"`Word.pos`:\", a_word_concurrunt.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CLTK contains classes a specific class for [the annotation types defined by v2 of the Universal Dependencies project](https://universaldependencies.org/u/feat/all.html). In the CLTK's codebase, these are located at [cltk/morphology/universal_dependencies_features.py](https://github.com/cltk/cltk/blob/dev/src/cltk/morphology/universal_dependencies_features.py).\n",
    "\n",
    "For instance, a Latin verb requires a label for its [https://universaldependencies.org/u/feat/all.html#al-u-feat/Mood](mood) (e.g., indicative), which the UD project defines as \"a feature that expresses modality and subclassifies finite verb forms\".\n",
    "\n",
    "Though morphological taggers may annnotate a verb's mood variously (\"ind.\", \"indicative\", \"Indic\", etc.), the CLTK maps the term into the following, standardized `Mood`.\n",
    "\n",
    "``` python\n",
    "class Mood(MorphosyntacticFeature):\n",
    "    \"\"\"The mood of a verb.\n",
    "    see https://universaldependencies.org/u/feat/Mood.html\n",
    "    \"\"\"\n",
    "\n",
    "    admirative = auto()\n",
    "    conditional = auto()\n",
    "    desiderative = auto()\n",
    "    imperative = auto()\n",
    "    indicative = auto()\n",
    "    jussive = auto()\n",
    "    necessitative = auto()\n",
    "    optative = auto()\n",
    "    potential = auto()\n",
    "    purposive = auto()\n",
    "    quotative = auto()\n",
    "    subjunctive = auto()\n",
    "```\n",
    "\n",
    "Turning back to the the above example word, we can see such features at `.features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(`Word.features`): <class 'cltk.morphology.morphosyntax.MorphosyntacticFeatureBundle'>\n",
      "\n",
      "`Word.features`: {Mood: [indicative], Number: [plural], Person: [third], Tense: [present], VerbForm: [finite], Voice: [active]}\n"
     ]
    }
   ],
   "source": [
    "# type\n",
    "print(\"type(`Word.features`):\", type(a_word_concurrunt.features))\n",
    "print(\"\")\n",
    "# str repr of `MorphosyntacticFeatureBundle`\n",
    "print(\"`Word.features`:\", a_word_concurrunt.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user may inspect a `MorphosyntacticFeatureBundle` in a manner similar to a `dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mood: [indicative]\n",
      "Number: [plural]\n",
      "Person: [third]\n",
      "Tense: [present]\n",
      "VerbForm: [finite]\n",
      "Voice: [active]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mood:\", a_word_concurrunt.features[\"Mood\"])  # type: List[Mood]\n",
    "print(\"Number:\", a_word_concurrunt.features[\"Number\"])  # type: List[Number]\n",
    "print(\"Person:\", a_word_concurrunt.features[\"Person\"])  # type: List[Person]\n",
    "print(\"Tense:\", a_word_concurrunt.features[\"Tense\"])  # type: List[Tense]\n",
    "print(\"VerbForm:\", a_word_concurrunt.features[\"VerbForm\"])  # type: List[VerbForm]\n",
    "print(\"Voice:\", a_word_concurrunt.features[\"Voice\"])  # type: List[Voice]\n",
    "\n",
    "# Note: The values returned here are a list, though under normally only one \n",
    "# morphological form will be available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking a bit closer at `MorphosyntacticFeature`, we can see how its data type inherits from the Python builtin [IntEnu](https://docs.python.org/3/library/enum.html#enum.IntEnum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(a_mood_obj): Mood\n",
      "\n",
      "Is `IntEnum`? True\n",
      "\n",
      "`Mood` inherits from `MorphosyntacticFeature`? True\n"
     ]
    }
   ],
   "source": [
    "a_mood_obj = a_word_concurrunt.features[\"Mood\"][0]\n",
    "# see type\n",
    "print(\"type(a_mood_obj):\", type(a_mood_obj))\n",
    "print(\"\")\n",
    "# See inheritance\n",
    "from enum import IntEnum\n",
    "print(\"Is `IntEnum`?\", isinstance(a_mood_obj, IntEnum))\n",
    "print(\"\")\n",
    "# \n",
    "from cltk.morphology.morphosyntax import MorphosyntacticFeature\n",
    "print(\"`Mood` inherits from `MorphosyntacticFeature`?\", isinstance(a_mood_obj, MorphosyntacticFeature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`MorphosyntacticFeature` accessors: ['_generate_next_value_', '_member_map_', '_member_names_', '_member_type_', '_missing_', '_name_', '_new_member_', '_sort_order_', '_unhashable_values_', '_use_args_', '_value2member_map_', '_value_', '_value_repr_', 'admirative', 'as_integer_ratio', 'bit_count', 'bit_length', 'conditional', 'conjugate', 'denominator', 'desiderative', 'from_bytes', 'gerundive', 'imag', 'imperative', 'indicative', 'infinitive', 'jussive', 'name', 'necessitative', 'numerator', 'optative', 'potential', 'purposive', 'quotative', 'real', 'subjunctive', 'to_bytes', 'value']\n",
      "\n",
      "MorphosyntacticFeature.name: indicative\n",
      "MorphosyntacticFeature.value: 6\n"
     ]
    }
   ],
   "source": [
    "# You can manipulate this object as any IntEnum plus a few extras\n",
    "\n",
    "print(\"`MorphosyntacticFeature` accessors:\", [x for x in dir(a_mood_obj) if not x.startswith(\"__\")])\n",
    "print(\"\")\n",
    "print(\"MorphosyntacticFeature.name:\", a_mood_obj.name)  # type: str\n",
    "# A stable int value is available, too, associated with this name\n",
    "print(\"MorphosyntacticFeature.value:\", a_mood_obj.value)  # type: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can create their own `MorphosyntacticFeature` and `MorphosyntacticFeatureBundle`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Mood: [subjunctive], Voice: [active], Person: [first], Number: [singular], VerbForm: [finite]}\n"
     ]
    }
   ],
   "source": [
    "from cltk.morphology.morphosyntax import MorphosyntacticFeatureBundle\n",
    "from cltk.morphology.universal_dependencies_features import Mood, Number, Person, VerbForm, Voice\n",
    "\n",
    "latin_word_sim = \"sim\"\n",
    "\n",
    "mood = Mood.subjunctive\n",
    "voice = Voice.active\n",
    "person = Person.first\n",
    "number = Number.singular\n",
    "verb_form = VerbForm.finite\n",
    "\n",
    "latin_word_sim_bundle = MorphosyntacticFeatureBundle(mood, voice, person, number, verb_form)\n",
    "print(latin_word_sim_bundle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This too can be interated through as `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mood [subjunctive]\n",
      "Voice [active]\n",
      "Person [first]\n",
      "Number [singular]\n",
      "VerbForm [finite]\n"
     ]
    }
   ],
   "source": [
    "for feature, value in latin_word_sim_bundle.items():\n",
    "    print(feature, value)  # Note: value has `list` type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we may even construct a `Word` with this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word(index_char_start=None, index_char_stop=None, index_token=None, index_sentence=None, string='sim', pos=None, lemma=None, stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={Mood: [subjunctive], Voice: [active], Person: [first], Number: [singular], VerbForm: [finite]}, category={}, stop=None, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n"
     ]
    }
   ],
   "source": [
    "from cltk.core.data_types import Word\n",
    "\n",
    "print(Word(string=\"sim\", features=latin_word_sim_bundle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more on this or any other CLTK class, use `help()`\n",
    "# help(a_mood_obj)\n",
    "# help(MorphosyntacticFeatureBundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Word.upos`: VERB\n",
      "`Word.xpos`: verb\n"
     ]
    }
   ],
   "source": [
    "# Note: Extra morphological info may be written in `str` type\n",
    "# to to the values at `.upos` and `.xpos` for languages using\n",
    "# Stanza project\n",
    "\n",
    "# Note: The particular annoations at these are often inconsistent across\n",
    "# languages or even treebanks within a single language; hence the benefit\n",
    "# of the CLTK's modeling at `.pos`.\n",
    "print(\"`Word.upos`:\", a_word_concurrunt.upos)\n",
    "print(\"`Word.xpos`:\", a_word_concurrunt.xpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling syntax with `Form` and `DependencyTree`  <a name=\"syntax\"></a>\n",
    "\n",
    "The CLTK uses the builtin `xml` library to build tree for modeling dependency parses. A `Word` is mapped into a `Form`, then `ElemntTree` is used to organize these `Form`s into a `DependencyTree`. With a tree, certain measurements are more efficient (counting depth, breadth, edge types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.dependency.tree import DependencyTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ibi egressi Troiani , ut quibus ab immenso prope errore nihil praeter arma et naues superesset , cum praedam ex agris agerent , Latinus rex Aborigines que qui tum ea tenebant loca ad arcendam vim advenarum armati ex urbe atque agris concurrunt .\n"
     ]
    }
   ],
   "source": [
    "# Let's look at this sentence again\n",
    "print(cltk_doc.sentences_strings[5])  # text form of `sentence_6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tree = DependencyTree.to_tree(sentence_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_dependencies'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[0;32m----> 3\u001b[0m pprint(\u001b[43ma_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dependencies\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_dependencies'"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(a_tree.get_dependencies())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'print_tree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_tree\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'print_tree'"
     ]
    }
   ],
   "source": [
    "a_tree.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction <a name=\"features\"></a>\n",
    "\n",
    "The CLTK offers the function `cltk_doc_to_features_table()`, which assist users when preparing a `Doc` for training data for machine learning. It converts the list of `Word` objects at `Doc.words` into a tabular list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.utils.feature_extraction import cltk_doc_to_features_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature_names, list_of_list_features \u001b[38;5;241m=\u001b[39m \u001b[43mcltk_doc_to_features_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcltk_doc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcltk_doc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cltk/src/cltk/utils/feature_extraction.py:70\u001b[0m, in \u001b[0;36mcltk_doc_to_features_table\u001b[0;34m(cltk_doc)\u001b[0m\n\u001b[1;32m     67\u001b[0m variable_names \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m feature_names\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Get dependency info\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m governing_word \u001b[38;5;241m=\u001b[39m \u001b[43mget_governor_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m pos_label_governor \u001b[38;5;241m=\u001b[39m get_pos(word\u001b[38;5;241m=\u001b[39mgoverning_word)\n\u001b[1;32m     72\u001b[0m word_features_list\u001b[38;5;241m.\u001b[39mappend(pos_label_governor)\n",
      "File \u001b[0;32m~/cltk/src/cltk/dependency/utils.py:17\u001b[0m, in \u001b[0;36mget_governor_word\u001b[0;34m(word, sentence)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m governor \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msentence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgovernor\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/cltk/src/cltk/core/data_types.py:115\u001b[0m, in \u001b[0;36mSentence.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Word:\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This indexing operation descends into the word list structure.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "feature_names, list_of_list_features = cltk_doc_to_features_table(cltk_doc=cltk_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See here the names of the features extracted\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of \"inner lists\" matches number of tokens\n",
    "print(\"Number tokens:\", len(cltk_doc.words))\n",
    "print(\"len() of feature instances (one for each token):\", len(list_of_list_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at one row of data `(variable name, variable value)`\n",
    "pprint(list(zip(feature_names, list_of_list_features[108])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief demonstration of `NLP()` for Ancient Greek <a name=\"greek-nlp\"></a>\n",
    "\n",
    "The API for Greek is the same as Latin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Ancient Greek file\n",
    "with open(\"grc-thucydides.txt\") as fo:\n",
    "    thucydides_full = fo.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Text snippet:\", thucydides_full[0:200])\n",
    "print(\"Character count:\", len(thucydides_full))\n",
    "print(\"Approximate token count:\", len(thucydides_full.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(thucydides_full) // 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut this down to roughly 10k tokens for this demonstration's purposes\n",
    "thucydides = thucydides_full[:len(thucydides_full) // 7]\n",
    "print(\"Approximate token count:\", len(thucydides.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thucydides[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cltk_nlp_grc = NLP(language=\"grc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution time is 50 sec on a 2015 Macbook Pro\n",
    "%time cltk_doc_grc = cltk_nlp_grc.analyze(text=thucydides)\n",
    "\n",
    "# You will be asked to download some models (from CLTK, fastText, and Stanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"`Doc.tokens`:\", cltk_doc_grc.tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc_grc.words[4])  # œÄœåŒªŒµŒºŒøŒΩ ('war')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tree_grc = DependencyTree.to_tree(cltk_doc_grc.sentences[0])  #81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(a_tree_grc.get_dependencies())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc_grc.sentences_strings[0])\n",
    "print(\"\")\n",
    "print(\"Translation:\", \"Thucydides, an Athenian, wrote the history of the war between the Peloponnesians and the Athenians, beginning at the moment that it broke out, and believing that it would be a great war, and more worthy of relation than any that had preceded it. This belief was not without its grounds. The preparations of both the combatants were in every department in the last state of perfection; and he could see the rest of the Hellenic race taking sides in the quarrel; those who delayed doing so at once having it in contemplation.\")\n",
    "print(\"\")\n",
    "a_tree_grc.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_grc, list_of_list_features_grc = cltk_doc_to_features_table(cltk_doc=cltk_doc_grc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_names_grc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len() of feature instances (one for each token):\", len(list_of_list_features_grc))\n",
    "print(\"\")\n",
    "print(\"Example of one instance row:\", list_of_list_features_grc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting these together for easier reading\n",
    "pprint(list(zip(feature_names_grc, list_of_list_features_grc[4])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

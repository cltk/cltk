"""Test ``cltk.corpora``."""

import os
import unittest
from unicodedata import normalize
from unittest.mock import patch

from cltk.corpora.grc.tlg.tlgu import TLGU
from cltk.utils.file_operations import make_cltk_path

# import nltk
#
# from cltk.corpus.greek.alphabet import expand_iota_subscript
# from cltk.corpus.greek.alphabet import filter_non_greek
# from cltk.corpus.greek.beta_to_unicode import Replacer
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_female_authors
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_epithet_index
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_epithets
# from cltk.corpus.greek.tlg.parse_tlg_indices import select_authors_by_epithet
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_epithet_of_author
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_geo_index
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_geographies
# from cltk.corpus.greek.tlg.parse_tlg_indices import select_authors_by_geo
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_geo_of_author
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_lists
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_id_author
# from cltk.corpus.greek.tlg.parse_tlg_indices import select_id_by_name
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_works_by_id
# from cltk.corpus.greek.tlg.parse_tlg_indices import check_id
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_date_author
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_dates
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_date_of_author
# from cltk.corpus.greek.tlg.parse_tlg_indices import _get_epoch
# from cltk.corpus.greek.tlg.parse_tlg_indices import _check_number
# from cltk.corpus.greek.tlg.parse_tlg_indices import _handle_splits
# from cltk.corpus.middle_english.alphabet import normalize_middle_english
# from cltk.corpus.old_norse import runes
# from cltk.corpus.utils.formatter import assemble_phi5_author_filepaths
# from cltk.corpus.utils.formatter import assemble_phi5_works_filepaths
# from cltk.corpus.utils.formatter import assemble_tlg_author_filepaths
# from cltk.corpus.utils.formatter import assemble_tlg_works_filepaths
# from cltk.corpus.utils.formatter import phi5_plaintext_cleanup
# from cltk.corpus.utils.formatter import remove_non_ascii
# from cltk.corpus.utils.formatter import remove_non_latin
# from cltk.corpus.utils.formatter import tonos_oxia_converter
# from cltk.corpus.utils.formatter import tlg_plaintext_cleanup
# from cltk.corpus.utils.formatter import cltk_normalize
# from cltk.corpus.utils.importer import CorpusImporter
# from cltk.corpus.utils.importer import CorpusImportError
# from cltk.corpus.sanskrit.itrans.itrans_transliterator import *
# from cltk.corpus.sanskrit.itrans.unicode_transliterate import *
# from cltk.corpus.sanskrit.itrans.langinfo import *
# from cltk.corpus.sanskrit.itrans.sinhala_transliterator import (
#     SinhalaDevanagariTransliterator as sdt,
# )
# from cltk.corpus.punjabi.numerifier import punToEnglish_number
# from cltk.corpus.punjabi.numerifier import englishToPun_number
# from cltk.corpus.egyptian.transliterate_mdc import mdc_unicode
# from cltk.corpus.aramaic.transliterate import square_to_imperial
# from cltk.corpus.utils.formatter import normalize_fr
# from cltk.corpus.swadesh import Swadesh
# from cltk.corpus.latin.latin_library_corpus_types import (
#     corpus_texts_by_type,
#     corpus_directories_by_type,
# )
# from cltk.utils.matrix_corpus_fun import distinct_words

__license__ = "MIT License. See LICENSE."

# DISTRIBUTED_CORPUS_PATH_REL = get_cltk_data_dir() + "/test_distributed_corpora.yaml"
# DISTRIBUTED_CORPUS_PATH = os.path.expanduser(DISTRIBUTED_CORPUS_PATH_REL)


class TestSequenceFunctions(unittest.TestCase):  # pylint: disable=R0904
    """Class for unittest"""

    @classmethod
    def setUpClass(self):
        pass
        # try:
        #     corpus_importer = CorpusImporter("latin")
        #     corpus_importer.import_corpus("latin_text_latin_library")
        #     corpus_importer.import_corpus("latin_text_perseus")
        #     corpus_importer = CorpusImporter("greek")
        #     corpus_importer.import_corpus("greek_text_perseus")
        #     corpus_importer.import_corpus("greek_text_tesserae")
        #     nltk.download("punkt")
        #     nltk.download("averaged_perceptron_tagger")
        # except:
        #     raise Exception("Failure to download test corpus")

    #
    # def test_greek_betacode_to_unicode(self):
    #     """Test converting Beta Code to Unicode.
    #     Note: assertEqual appears to not be correctly comparing certain
    #     characters (``Î¬`` and ``Î¯``, at least).
    #     """
    #     replacer = Replacer()
    #     # Generic test
    #     beta_1 = r"""O(/PWS OU)=N MH\ TAU)TO\ """
    #     unicode_1 = replacer.beta_code(beta_1)
    #     target_1 = "á½…Ï€Ï‰Ï‚ Î¿á½–Î½ Î¼á½´ Ï„Î±á½Ï„á½¸ "
    #     # Test for iota and diaeresis
    #     self.assertEqual(unicode_1, target_1)
    #     beta_2 = r"""*XALDAI+KH\N"""
    #     unicode_2 = replacer.beta_code(beta_2)
    #     target_2 = "Î§Î±Î»Î´Î±ÏŠÎºá½´Î½"
    #     self.assertEqual(unicode_2, target_2)
    #     # Test for upsilon and diaeresis
    #     beta_3 = r"""PROU+POTETAGME/NWN"""
    #     unicode_3 = replacer.beta_code(beta_3)
    #     target_3 = "Ï€ÏÎ¿Ï‹Ï€Î¿Ï„ÎµÏ„Î±Î³Î¼Î­Î½Ï‰Î½"
    #     self.assertEqual(unicode_3, target_3)
    #     # Test for lowercase
    #     beta_4 = r"""proi+sxome/nwn"""
    #     unicode_4 = replacer.beta_code(beta_4)
    #     target_4 = "Ï€ÏÎ¿ÏŠÏƒÏ‡Î¿Î¼Î­Î½Ï‰Î½"
    #     self.assertEqual(unicode_4, target_4)

    def test_tlgu_init(self):
        """Test constructors of TLGU module for check, import, and install."""
        TLGU(interactive=False)
        header_file = make_cltk_path("grc/software/grc_software_tlgu/README.md")
        self.assertTrue(os.path.isfile(header_file))


#     def test_import_greek_software_tlgu(self):
#         """Test instantiating TLGU(). This will download and install
#         the software, if necessary.
#         """
#         corpus_importer = CorpusImporter("greek")
#         corpus_importer.import_corpus("greek_software_tlgu")
#         file_rel = os.path.join(
#             get_cltk_data_dir() + "/greek/software/greek_software_tlgu/README.md"
#         )
#         _file = os.path.expanduser(file_rel)
#         file_exists = os.path.isfile(_file)
#         self.assertTrue(file_exists)
#
#     def test_tlgu_convert(self):
#         """Test TLGU convert. This reads the file
#         ``tlgu_test_text_beta_code.txt``, which mimics a TLG file, and
#         converts it.
#         Note: assertEqual fails on some accented characters ('Î®', 'Î¯').
#         """
#         in_test = os.path.abspath("cltk/tests/test_nlp/tlgu_test_text_beta_code.txt")
#         out_test = os.path.normpath(get_cltk_data_dir() + "/tlgu_test_text_unicode.txt")
#         tlgu = TLGU(testing=True)
#         tlgu.convert(in_test, out_test)
#         with open(out_test) as out_file:
#             new_text = out_file.read()
#         os.remove(out_test)
#         target = """
# Î²Î»Î»Î¿Î½ Î´' á¼€Î»Î»Î»Î¿Ï…Ï‚ Ï‡Î±Î»ÎºÏÎµÏƒÎ¹Î½ á¼Î³Ï‡Îµá¿ƒÏƒÎ¹Î½.
# """
#         self.assertEqual(new_text, target)
#
#     def test_tlgu_convert_fail(self):
#         """Test the TLGU to fail when importing a corpus that doesn't exist."""
#         tlgu = TLGU(testing=True)
#         with self.assertRaises(AssertionError):
#             tlgu.convert(
#                 "~/Downloads/corpora/TLG_E/bad_path.txt", "~/Documents/thucydides.txt"
#             )
#
#     def test_tlgu_convert_corpus_fail(self):
#         """Test the TLGU to fail when trying to convert an unsupported corpus."""
#         tlgu = TLGU(testing=True)
#         with self.assertRaises(AssertionError):
#             tlgu.convert_corpus(corpus="bad_corpus")
#
#     def test_tlg_plaintext_cleanup(self):
#         """Test post-TLGU cleanup of text of Greek TLG text."""
#         dirty = """{Î‘Î˜Î—ÎÎ‘Î™ÎŸÎ¥ ÎÎ‘Î¥ÎšÎ¡Î‘Î¤Î™Î¤ÎŸÎ¥ Î”Î•Î™Î ÎÎŸÎ£ÎŸÎ¦Î™Î£Î¤Î©Î} LATIN á¼ˆÎ¸Î®Î½Î±Î¹Î¿Ï‚ (Î¼á½²Î½) á½ Ï„á¿†Ï‚ 999 Î²Î¯Î²Î»Î¿Ï… âŒ©Ï€Î±Ï„Î®ÏâŒª: Ï€Î¿Î¹Îµá¿–Ï„Î±Î¹ Î´á½² Ï„á½¸Î½ Î»ÏŒÎ³Î¿Î½ Ï€Ïá½¸Ï‚ Î¤Î¹Î¼Î¿ÎºÏÎ¬Ï„Î·Î½."""  # pylint: disable=line-too-long
#         clean = tlg_plaintext_cleanup(dirty, rm_punctuation=True, rm_periods=False)
#         target = " á¼ˆÎ¸Î®Î½Î±Î¹Î¿Ï‚ Î¼á½²Î½ á½ Ï„á¿†Ï‚ Î²Î¯Î²Î»Î¿Ï… Ï€Î±Ï„Î®Ï Ï€Î¿Î¹Îµá¿–Ï„Î±Î¹ Î´á½² Ï„á½¸Î½ Î»ÏŒÎ³Î¿Î½ Ï€Ïá½¸Ï‚ Î¤Î¹Î¼Î¿ÎºÏÎ¬Ï„Î·Î½."
#         self.assertEqual(clean, target)
#
#     def test_tlg_plaintext_cleanup_rm_periods(self):
#         """Test post-TLGU cleanup of text of Greek TLG text."""
#         dirty = """{Î‘Î˜Î—ÎÎ‘Î™ÎŸÎ¥ ÎÎ‘Î¥ÎšÎ¡Î‘Î¤Î™Î¤ÎŸÎ¥ Î”Î•Î™Î ÎÎŸÎ£ÎŸÎ¦Î™Î£Î¤Î©Î} LATIN á¼ˆÎ¸Î®Î½Î±Î¹Î¿Ï‚ (Î¼á½²Î½) á½ Ï„á¿†Ï‚ 999 Î²Î¯Î²Î»Î¿Ï… âŒ©Ï€Î±Ï„Î®ÏâŒª: Ï€Î¿Î¹Îµá¿–Ï„Î±Î¹ Î´á½² Ï„á½¸Î½ Î»ÏŒÎ³Î¿Î½ Ï€Ïá½¸Ï‚ Î¤Î¹Î¼Î¿ÎºÏÎ¬Ï„Î·Î½."""  # pylint: disable=line-too-long
#         clean = tlg_plaintext_cleanup(dirty, rm_punctuation=True, rm_periods=True)
#         target = " á¼ˆÎ¸Î®Î½Î±Î¹Î¿Ï‚ Î¼á½²Î½ á½ Ï„á¿†Ï‚ Î²Î¯Î²Î»Î¿Ï… Ï€Î±Ï„Î®Ï Ï€Î¿Î¹Îµá¿–Ï„Î±Î¹ Î´á½² Ï„á½¸Î½ Î»ÏŒÎ³Î¿Î½ Ï€Ïá½¸Ï‚ Î¤Î¹Î¼Î¿ÎºÏÎ¬Ï„Î·Î½"
#         self.assertEqual(clean, target)
#
#     def test_phi5_plaintext_cleanup(self):
#         """Test post-TLGU cleanup of text of Latin PHI5 text."""
#         dirty = """        {ODYSSIA}
#         {Liber I}
# Virum Ã¡ge 999 mihi, Camena, (insece) versutum.
# Pater noster, Saturni filie . . .
# Mea puera, quid verbi ex tuo ore supera fugit?
# argenteo polubro, aureo eclutro. """
#         clean = phi5_plaintext_cleanup(dirty, rm_punctuation=True, rm_periods=False)
#         target = " Virum Ã¡ge mihi Camena versutum. Pater noster Saturni filie . . . Mea puera quid verbi ex tuo ore supera fugit argenteo polubro aureo eclutro. "  # pylint: disable=line-too-long
#         self.assertEqual(clean, target)
#
#     def test_phi5_plaintext_cleanup_rm_periods(self):
#         """Test post-TLGU cleanup of text of Latin PHI5 text."""
#         dirty = """        {ODYSSIA}
#         {Liber I}
# Virum Ã¡ge 999 mihi, Camena, (insece) versutum.
# Pater noster, Saturni filie . . .
# Mea puera, quid verbi ex tuo ore supera fugit?
# argenteo polubro, aureo eclutro. """
#         clean = phi5_plaintext_cleanup(dirty, rm_punctuation=True, rm_periods=True)
#         target = " Virum Ã¡ge mihi Camena versutum Pater noster Saturni filie Mea puera quid verbi ex tuo ore supera fugit argenteo polubro aureo eclutro "  # pylint: disable=line-too-long
#         self.assertEqual(clean, target)
#
#     def test_phi5_plaintext_cleanup_rm_periods_bytes(self):
#         """Test post-TLGU cleanup of text of Latin PHI5 text."""
#         dirty = "\xcc\x81 Virum Ã¡ge 999 mihi."
#         clean = phi5_plaintext_cleanup(dirty, rm_punctuation=True, rm_periods=True)
#         target = "ÃŒÂ Virum Ã¡ge mihi"
#         self.assertEqual(clean, target)
#
#     def test_cltk_normalize_compatible(self):
#         """Test Normalizing Text with compatibility True"""
#         s1 = "cafeÌ"
#         s2 = "cafe\u0301"
#         normalized_text = cltk_normalize(s1, compatibility=True)
#         target = normalize("NFKC", s2)
#         self.assertEqual(normalized_text, target)
#
#     def test_cltk_normalize_noncompatible(self):
#         """Test Normalizing Text with compatibility False"""
#         s1 = "cafeÌ"
#         s2 = "cafe\u0301"
#         normalized_text = cltk_normalize(s1, compatibility=False)
#         target = normalize("NFC", s2)
#         self.assertEqual(normalized_text, target)
#
#     def test_assemble_tlg_author(self):
#         """Test building absolute filepaths from TLG index."""
#         paths = assemble_tlg_author_filepaths()
#         self.assertEqual(len(paths), 1823)
#
#     def test_assemble_phi5_author(self):
#         """Test building absolute filepaths from TLG index."""
#         paths = assemble_phi5_author_filepaths()
#         self.assertEqual(len(paths), 362)
#
#     def test_assemble_tlg_works(self):
#         """"Test building absolute filepaths from TLG works index."""
#         paths = assemble_tlg_works_filepaths()
#         self.assertEqual(len(paths), 6625)
#
#     def test_assemble_phi5_works(self):
#         """"Test building absolute filepaths from PHI5 works index."""
#         paths = assemble_phi5_works_filepaths()
#         self.assertEqual(len(paths), 836)
#
#     def test_corpora_import_list_greek(self):
#         """Test listing of available corpora."""
#         corpus_importer = CorpusImporter("greek")
#         available_corpora = corpus_importer.list_corpora
#         self.assertTrue(available_corpora)
#
#     def test_corpora_import_list_latin(self):
#         """Test listing of available corpora."""
#         corpus_importer = CorpusImporter("latin")
#         available_corpora = corpus_importer.list_corpora
#         self.assertTrue(available_corpora)
#
#     def test_tonos_oxia_converter(self):
#         """Test function converting tonos to oxia accent."""
#         char_tonos = "Î¬"  # with tonos, for Modern Greek
#         char_oxia = "á½±"  # with oxia, for Ancient Greek
#         corrected = tonos_oxia_converter(char_tonos)
#         self.assertEqual(char_oxia, corrected)
#
#     def test_tonos_oxia_converter_reverse(self):
#         """Test function converting tonos to oxia accent."""
#         char_tonos = "Î¬"  # with tonos, for Modern Greek
#         char_oxia = "Î¬"  # with oxia, for Ancient Greek
#         corrected = tonos_oxia_converter(char_oxia, reverse=True)
#         self.assertEqual(char_tonos, corrected)
#
#     def test_remove_non_ascii(self):
#         """Test removing all non-ascii characters from a string."""
#         non_ascii_str = "Ascii and some non-ascii: Î¸ÎµÎ¿á½ºÏ‚ Î¼á½²Î½ Î±á¼°Ï„á¿¶ Ï„á¿¶Î½Î´á¾½ á¼€Ï€Î±Î»Î»Î±Î³á½´Î½"  # pylint: disable=line-too-long
#         ascii_str = remove_non_ascii(non_ascii_str)
#         valid = "Ascii and some non-ascii:     "
#         self.assertEqual(ascii_str, valid)
#
#     def test_remove_non_latin(self):
#         """Test removing all non-Latin characters from a string."""
#         latin_str = "(1) Dices á¼ÏƒÏ„Î¹Î½ á¼Î¼ÏŒÏ‚ pulchrum esse inimicos ulcisci."  # pylint: disable=line-too-long
#         non_latin_str = remove_non_latin(latin_str)
#         valid = " Dices   pulchrum esse inimicos ulcisci"
#         self.assertEqual(non_latin_str, valid)
#
#     def test_remove_non_latin_opt(self):
#         """Test removing all non-Latin characters from a string, with
#         `also_keep` parameter.
#         """
#         latin_str = "(1) Dices á¼ÏƒÏ„Î¹Î½ á¼Î¼ÏŒÏ‚ pulchrum esse inimicos ulcisci."  # pylint: disable=line-too-long
#         non_latin_str = remove_non_latin(latin_str, also_keep=[".", ","])
#         valid = " Dices   pulchrum esse inimicos ulcisci."
#         self.assertEqual(non_latin_str, valid)

#     def test_import_lat_text_lat_lib(self):
#         """Test cloning the Latin Library text corpus."""
#         corpus_importer = CorpusImporter("latin")
#         corpus_importer.import_corpus("latin_text_latin_library")
#         file_rel = os.path.join(
#             get_cltk_data_dir() + "/latin/text/latin_text_latin_library/README.md"
#         )
#         _file = os.path.expanduser(file_rel)
#         file_exists = os.path.isfile(_file)
#         self.assertTrue(file_exists)
#
#     def test_import_latin_models_cltk(self):
#         """Test cloning the CLTK Latin models."""
#         corpus_importer = CorpusImporter("latin")
#         corpus_importer.import_corpus("latin_models_cltk")
#         file_rel = os.path.join(
#             get_cltk_data_dir() + "/latin/model/latin_models_cltk/README.md"
#         )
#         _file = os.path.expanduser(file_rel)
#         file_exists = os.path.isfile(_file)
#         self.assertTrue(file_exists)
#
#     def test_import_greek_models_cltk(self):
#         """Test pull (not clone) the CLTK Greek models. Import was run in
#         ``setUp()``.
#         """
#         corpus_importer = CorpusImporter("greek")
#         corpus_importer.import_corpus("greek_models_cltk")
#         file_rel = os.path.join(
#             get_cltk_data_dir() + "/greek/model/greek_models_cltk/README.md"
#         )
#         _file = os.path.expanduser(file_rel)
#         file_exists = os.path.isfile(_file)
#         self.assertTrue(file_exists)
#
#     def test_show_corpora_bad_lang(self):
#         """Test failure of importer upon selecting unsupported language."""
#         with self.assertRaises(CorpusImportError):
#             CorpusImporter("bad_lang")
#
#     def test_import_nonexistant_corpus(self):
#         """Test that creating a CorpusImporter for a non existent lang
#            fails smoothly
#         """
#         with self.assertRaises(CorpusImportError):
#             corpus_importer = CorpusImporter("greek")
#             corpus_importer.import_corpus("euclids_book_of_recipes")
#
#     def test_import_latin_text_antique_digiliblt(self):
#         """Test cloning the Antique Latin from digilibLT."""
#         corpus_importer = CorpusImporter("latin")
#         corpus_importer.import_corpus("latin_text_antique_digiliblt")
#         file_rel = os.path.join(
#             get_cltk_data_dir() + "/latin/text/latin_text_antique_digiliblt/README.md"
#         )
#         _file = os.path.expanduser(file_rel)
#         file_exists = os.path.isfile(_file)
#         self.assertTrue(file_exists)
#
#     def test_get_female_authors(self):
#         """Test function to parse TLG female authors list."""
#         authors = get_female_authors()
#         authors = sorted(authors)[:3]
#         self.assertEqual(authors, ["0009", "0051", "0054"])
#
#     def test_get_epithet_index(self):
#         """Test get_epithet_index()."""
#         ind = get_epithet_index()
#         self.assertEqual(type(ind), dict)
#
#     def test_get_epithets(self):
#         """Test get_epithets()."""
#         epithets = get_epithets()
#         self.assertEqual(epithets[:2], ["Alchemistae", "Apologetici"])
#
#     def test_select_authors_by_epithet(self):
#         """Test select_authors_by_epithet()."""
#         authors = select_authors_by_epithet("Apologetici")
#         self.assertEqual(len(authors), 9)
#
#     def test_get_epithet_of_author(self):
#         """Test get_epithet_of_author()."""
#         epithet = get_epithet_of_author("0016")
#         self.assertEqual(epithet, "Historici/-ae")
#
#     def test_get_geo_index(self):
#         """Test get_geo_index()."""
#         index = get_geo_index()
#         self.assertEqual(type(index), dict)
#
#     def test_get_geographies(self):
#         """Test get_geographies()."""
#         geos = get_geographies()
#         self.assertEqual(type(geos), list)
#
#     def test_select_authors_by_geo(self):
#         """Test select_authors_by_geo()."""
#         authors = select_authors_by_geo("Athenae")
#         self.assertEqual(len(authors), 113)
#
#     def test_get_geo_of_author(self):
#         """Test get_geo_of_author()."""
#         geo = get_geo_of_author("0008")
#         self.assertEqual(geo, "Naucratis")
#
#     def test_get_lists(self):
#         """Test get_lists()."""
#         index = get_lists()
#         self.assertEqual(type(index), dict)
#
#     def test_get_id_author(self):
#         """Test get_id_author()."""
#         self.assertEqual(type(get_id_author()), dict)
#
#     def test_select_id_by_name(self):
#         """Test select_id_by_name()."""
#         matches = select_id_by_name("hom")
#         self.assertEqual(len(matches), 11)
#
#     def test_get_works_by_id(self):
#         """Test get_works_by_id()."""
#         works = get_works_by_id("0007")
#         self.assertEqual(len(works), 147)
#
#     def test_check_id(self):
#         """Test check_id"""
#         author = check_id("0557")
#         valid = "Epictetus Phil."
#         self.assertEqual(author, valid)
#
#     # #! Figure out why this test stopped working (actual function runs fine)
#     # def test_get_date_author(self):
#     #     """Test get_date_author()."""
#     #     dates = get_date_author()
#     #     self.assertEqual(type(dates), dict)
#
#     # #! Figure out why this test stopped working (actual function runs fine)
#     # def test_get_dates(self):
#     #     """Test get_dates()."""
#     #     dates = get_dates()
#     #     self.assertEqual(type(dates), list)
#     #     self.assertEqual(len(dates), 183)
#
#     # #! Figure out why this test stopped working (actual function runs fine)
#     # def test_get_date_of_author(self):
#     #     """Test get_date_of_author()."""
#     #     self.assertEqual(get_date_of_author('1747'), '1 B.C./A.D. 1')
#     #     self.assertEqual(get_date_of_author('1143'), '2-1 B.C.')
#     #     self.assertEqual(get_date_of_author('0295'), 'Varia')
#     #     self.assertEqual(get_date_of_author('4304'), 'a. A.D. 10')
#     #     self.assertIsNone(get_date_of_author('123456'))
#
#     def test_get_epoch(self):
#         """Test _get_epoch()."""
#         self.assertEqual(_get_epoch("A.D. 9-10"), "ad")
#         self.assertEqual(_get_epoch("p. A.D. 2"), "ad")
#         self.assertIsNone(_get_epoch("a. A.D. 2"))
#         self.assertEqual(_get_epoch("3 B.C."), "bc")
#         self.assertIsNone(_get_epoch("p. 7 B.C."))
#         self.assertEqual(_get_epoch("a. 1 B.C."), "bc")
#         self.assertEqual(_get_epoch("a. 1 B.C.?"), "bc")
#
#     def test_check_number(self):
#         """Test _check_number()."""
#         self.assertTrue(_check_number("5"))
#         self.assertTrue(_check_number("5?"))
#         self.assertFalse(_check_number("A.D. 5"))
#         self.assertFalse(_check_number("A.D. 5?"))
#         self.assertFalse(_check_number("p. 4 B.C."))
#
#     def test_handle_splits(self):
#         """Test _handle_splits()."""
#         _dict = {
#             "start_raw": "A.D. 9",
#             "start_epoch": "ad",
#             "stop_epoch": "ad",
#             "stop_raw": "A.D. 10",
#         }
#         self.assertEqual(_handle_splits("A.D. 9-10"), _dict)
#         _dict = {
#             "start_raw": "A.D. 1?",
#             "start_epoch": "ad",
#             "stop_epoch": "ad",
#             "stop_raw": "A.D. 6",
#         }
#         self.assertEqual(_handle_splits("A.D. 1?-6"), _dict)
#         _dict = {
#             "stop_raw": "p. A.D. 2",
#             "start_raw": "a. 4 B.C.",
#             "stop_epoch": "ad",
#             "start_epoch": "bc",
#         }
#         self.assertEqual(_handle_splits("a. 4 B.C.-p. A.D. 2"), _dict)
#         _dict = {
#             "stop_raw": "A.D. 2?",
#             "start_raw": "A.D. 2?",
#             "stop_epoch": "ad",
#             "start_epoch": "ad",
#         }
#         self.assertEqual(_handle_splits("A.D. 2?"), _dict)
#         _dict = {
#             "stop_raw": "1 B.C.?",
#             "start_raw": "2 B.C.?",
#             "stop_epoch": "bc",
#             "start_epoch": "bc",
#         }
#         self.assertEqual(_handle_splits("2/1 B.C.?"), _dict)
#
#     def test_punjabi_to_english_number_conversion(self):
#         str_test = "à©§à©¨à©©à©ªà©«à©¬à©­à©®à©¯à©¦"
#         self.assertEqual(1234567890, punToEnglish_number(str_test))
#
#     def test_englishToPun_number(self):
#         str_test = "à©§à©¨à©©à©ªà©«à©¬à©­à©®à©¯à©¦"
#         self.assertEqual(str_test, englishToPun_number(1234567890))
#
#     def test_english_to_punjabi_number_conversion(self):
#         """Test English to Punjabi number conversion."""
#         str_test = "à©§à©¨à©©à©ªà©«à©¬à©­à©®à©¯à©¦"
#         self.assertEqual(str_test, englishToPun_number(1234567890))
#
#     def make_distributed_corpora_testing_file(self):
#         """Setup for some cloning tests, make file at
#         get_cltk_data_dir() + '/test_distributed_corpora.yaml'.
#         """
#         # ! Don't format this literal string, must be YAML-ish
#         yaml_str_to_write = """example_distributed_latin_corpus:
#         git_remote: git@github.com:kylepjohnson/latin_corpus_newton_example.git
#         language: latin
#         type: text
#
# example_distributed_fake_language_corpus:
#         origin: git@github.com:kylepjohnson/doesntexistyet.git
#         language: fake_language
#         type: treebank
#     """
#         cltk_data_dir = get_cltk_data_dir()
#         if not os.path.isdir(cltk_data_dir):
#             os.mkdir(cltk_data_dir)
#         with open(DISTRIBUTED_CORPUS_PATH, "w") as file_open:
#             file_open.write(yaml_str_to_write)
#
#     def remove_distributed_corpora_testing_file(self):
#         """Remove ~/cltk_data/test_distributed_corpora.yaml."""
#         os.remove(DISTRIBUTED_CORPUS_PATH)
#
#     def test_corpus_importer_variables_no_user_but_in_core(self):
#         """Test function which checks for presence of
#         ~/cltk_data/distributed_corpora.yaml. Look for a language
#         not in core repos but not in user-defined.
#         """
#         self.make_distributed_corpora_testing_file()
#         corpus_importer = CorpusImporter("sanskrit", testing=True)
#         self.assertIn("sanskrit_models_cltk", corpus_importer.list_corpora)
#         self.remove_distributed_corpora_testing_file()
#
#     def test_corpus_importer_variables_user_but_not_core(self):
#         """Test function which checks for presence of
#         `~/cltk_data/distributed_corpora.yaml`. Look for a language
#         not in the core but in the user's custom file.
#         """
#         self.make_distributed_corpora_testing_file()
#         corpus_importer = CorpusImporter("fake_language", testing=True)
#         corpus_name = corpus_importer.list_corpora
#         target_name = "example_distributed_fake_language_corpus"
#         self.assertEqual(corpus_name[0], target_name)
#         self.remove_distributed_corpora_testing_file()
#
#     def test_corpus_importer_variables_no_user_but_yes_core(self):
#         """Test function which checks for presence of
#         `~/cltk_data/distributed_corpora.yaml`. Look for a language
#         in the core but not in the user's custom file.
#         """
#         self.make_distributed_corpora_testing_file()
#         corpus_importer = CorpusImporter("pali", testing=True)
#         corpora = corpus_importer.list_corpora
#         self.assertIn("pali_text_ptr_tipitaka", corpora)
#         self.remove_distributed_corpora_testing_file()
#
#     def test_corpus_importer_variables_no_user_no_core(self):
#         """Test function which checks for presence of
#         `~/cltk_data/distributed_corpora.yaml`. Look for a language
#         neither in the core or in the user's custom file.
#         """
#         self.make_distributed_corpora_testing_file()
#         with self.assertRaises(CorpusImportError):
#             CorpusImporter("fake_language_nowhere")
#         self.remove_distributed_corpora_testing_file()
#
#     #
#     # def test_import_punjabi_punjabi_text_gurban(self):
#     #     pun_import = CorpusImporter('punjabi')
#     #     corpora_list = pun_import.list_corpora
#     #     self.assertTrue('punjabi_text_gurban' in corpora_list)
#     #     pun_import.import_corpus('punjabi_text_gurban')
#     #     file_path = os.path.join(get_cltk_data_dir() + '/punjabi/text/punjabi_text_gurban/README.md')
#     #     _file = os.path.expanduser(file_path)
#     #     self.assertTrue(os.path.isfile(_file))
#     #
#     # Ancient Egyptian Stuff -----------------------------
#
#     def test_egyptian_transliterate_mdc_to_unicode_q_kopf_True(self):
#         """
#         test to transliterate mdc to unicode
#         for ancient egyptian texts.
#         q_kopf option True
#         """
#         #
#         mdc_string = """ink Smsw Sms nb=f bAk n ipt nswt
#         irt pat wrt <Hswt> Hmt [nswt] snwsrt m Xnm-swt
#         sAt nswt imn-m-HAt m
#         qA-nfrw nfrw nbt imAx"""
#         #
#         test_result_string = mdc_unicode(mdc_string)
#         #
#         comparison_string = """iÒ†nk Å¡msw Å¡ms nbâ¸—f bêœ£k n iÒ†pt nswt
#         iÒ†rt pêœ¥t wrt âŒ©á¸¥swtâŒª á¸¥mt [nswt] snwsrt m áº–nm-swt
#         sêœ£t nswt iÒ†mn-m-á¸¥êœ£t m
#         qêœ£-nfrw nfrw nbt iÒ†mêœ£á¸«"""
#         #
#         self.assertEqual(test_result_string, comparison_string)
#
#     def test_egyptian_transliterate_mdc_to_unicode_q_kopf_False(self):
#         """
#         test to transliterate mdc to unicode
#         for ancient egyptian texts.
#         q_kopf option False
#         """
#         #
#         mdc_string = """ink Smsw Sms nb=f bAk n ipt nswt
#         irt pat wrt <Hswt> Hmt [nswt] snwsrt m Xnm-swt
#         sAt nswt imn-m-HAt m
#         qA-nfrw nfrw nbt imAx"""
#         #
#         test_result_string = mdc_unicode(mdc_string, q_kopf=False)
#         #
#         comparison_string = """iÒ†nk Å¡msw Å¡ms nbâ¸—f bêœ£k n iÒ†pt nswt
#         iÒ†rt pêœ¥t wrt âŒ©á¸¥swtâŒª á¸¥mt [nswt] snwsrt m áº–nm-swt
#         sêœ£t nswt iÒ†mn-m-á¸¥êœ£t m
#         á¸³êœ£-nfrw nfrw nbt iÒ†mêœ£á¸«"""
#         #
#         self.assertEqual(test_result_string, comparison_string)
#
#     def test_square_to_imperial_(self):
#         "test square_to_imperial function"
#         square_script = "×¤×“×™ ×‘×¨ ×“×’[× ]××œ×š ×œ××—× ×‘×¨ ×—×¤×™×• × ×ª× ×ª ×œ×š"
#         imperial_version = "ğ¡ğ¡ƒğ¡‰ ğ¡ğ¡“ ğ¡ƒğ¡‚[ğ¡]ğ¡Œğ¡‹ğ¡Š ğ¡‹ğ¡€ğ¡‡ğ¡€ ğ¡ğ¡“ ğ¡‡ğ¡ğ¡‰ğ¡… ğ¡ğ¡•ğ¡ğ¡• ğ¡‹ğ¡Š"
#         result = square_to_imperial(square_script)
#         self.assertEqual(imperial_version, result)
#
#     def test_expand_iota_subscript(self):
#         """Test subscript expander."""
#         unexpanded = "Îµá¼° Î´á½² ÎºÎ±á½¶ Ï„á¿· á¼¡Î³ÎµÎ¼ÏŒÎ½Î¹ Ï€Î¹ÏƒÏ„ÎµÏÏƒÎ¿Î¼ÎµÎ½ á½ƒÎ½ á¼‚Î½ Îšá¿¦ÏÎ¿Ï‚ Î´Î¹Î´á¿·"
#         expanded = expand_iota_subscript(unexpanded)
#         target = "Îµá¼° Î´á½² ÎºÎ±á½¶ Ï„á¿¶Î™ á¼¡Î³ÎµÎ¼ÏŒÎ½Î¹ Ï€Î¹ÏƒÏ„ÎµÏÏƒÎ¿Î¼ÎµÎ½ á½ƒÎ½ á¼‚Î½ Îšá¿¦ÏÎ¿Ï‚ Î´Î¹Î´á¿¶Î™"
#         self.assertEqual(expanded, target)
#
#     def test_expand_iota_subscript_lower(self):
#         """Test subscript expander."""
#         unexpanded = "Îµá¼° Î´á½² ÎºÎ±á½¶ Ï„á¿· á¼¡Î³ÎµÎ¼ÏŒÎ½Î¹ Ï€Î¹ÏƒÏ„ÎµÏÏƒÎ¿Î¼ÎµÎ½ á½ƒÎ½ á¼‚Î½ Îšá¿¦ÏÎ¿Ï‚ Î´Î¹Î´á¿·"
#         expanded = expand_iota_subscript(unexpanded, lowercase=True)
#         target = "Îµá¼° Î´á½² ÎºÎ±á½¶ Ï„á¿¶Î¹ á¼¡Î³ÎµÎ¼ÏŒÎ½Î¹ Ï€Î¹ÏƒÏ„ÎµÏÏƒÎ¿Î¼ÎµÎ½ á½ƒÎ½ á¼‚Î½ Îºá¿¦ÏÎ¿Ï‚ Î´Î¹Î´á¿¶Î¹"
#         self.assertEqual(expanded, target)
#
#     #
#     def test_filter_non_greek(self):
#         """
#         Test filter non greek characters in a mixed string.
#         """
#         test_input_string = (
#             "[á¼™ÎºÎ±]Ï„á½¹Î¼Î±Î½Î´[ÏÎ¿Ï‚ Î‘á¼°ÏƒÏ‡]Ïá½·Ï‰Î½Î¿Ï‚ â‹® á¼ˆÏ[Î¹ÏƒÏ„Îµá½·Î´Î·..c5..]"  # PH247029, line 2
#         )
#         comparison_string = "á¼™ÎºÎ±Ï„Î¼Î±Î½Î´ÏÎ¿Ï‚ Î‘á¼°ÏƒÏ‡ÏÏ‰Î½Î¿Ï‚  á¼ˆÏÎ¹ÏƒÏ„ÎµÎ´Î·"
#         test_result_string = filter_non_greek(test_input_string)
#         #
#         self.assertEqual(test_result_string, comparison_string)
#
#     def test_normalize(self):
#         """
#         Test french normalizer
#         """
#         text = "viw"
#         normalized = normalize_fr(text)
#         target = ["vieux"]
#         self.assertEqual(normalized, target)
#
#     def test_normalize_middle_english(self):
#         """Tests ME normalizer"""
#         in_test = "'Madame,' quod he, 'reule me As È,e ly:k?eÃ¾ best.'"
#         target = "'madame' quod he 'reule me as ye lyketh best'"
#         test = normalize_middle_english(in_test)
#         self.assertEqual(target, test)
#
#
# class TestUnicode(unittest.TestCase):
#     "Test py23char"
#
#     def test_py23char(self):
#         self.assertEqual(py23char(0x92D), "à¤­")
#         self.assertFalse(py23char(0x93D) == "à¤­")
#
#
# class TestTransliteration(unittest.TestCase):
#     "Test the transliteration in corpus.sanskrit"
#
#     def test_Indicization(
#         self,
#     ):  # Test ItransTransliterator - Convert from Itrans to Devanagari
#         x = ItransTransliterator.from_itrans("pitL^In", "hi")
#         y = ItransTransliterator.from_itrans("yogazcittavRttinirodhaH", "hi")
#         z = ItransTransliterator.from_itrans("yogazcittavRttinirodhaH", "badVar")
#         self.assertEqual(x, "à¤ªà¤¿à¤¤à¥£à¤¨à¥")
#         self.assertEqual(y, "à¤¯à¥‹à¤—à¤¶à¥à¤šà¤¿à¤¤à¥à¤¤à¤µà¥à¤±à¥à¤¤à¥à¤¤à¤¿à¤¨à¤¿à¤°à¥‹à¤§à¤ƒ")
#         self.assertEqual(z, "yogazcittavRttinirodhaH")
#
#     def test_ScriptConversion(
#         self,
#     ):  # Test UnicodeIndicTransliterator - Convert between various scripts
#         x = UnicodeIndicTransliterator.transliterate("à¤°à¤¾à¤œà¤¸à¥à¤¥à¤¾à¤¨", "hi", "pa")
#         self.assertEqual(x, "à¨°à¨¾à¨œà¨¸à©à¨¥à¨¾à¨¨")
#         y = UnicodeIndicTransliterator.transliterate("à·ƒà·’à¶‚à·„à¶½ à¶…à¶šà·Šà·‚à¶» à¶¸à·à¶½à·à·€", "si", "hi")
#         self.assertEqual(y, "à¤¸à¤¿à¤‚à¤¹à¤² à¤…à¤•à¥à¤·à¤° à¤®à¤¾à¤²à¤¾à¤µ")
#         z = UnicodeIndicTransliterator.transliterate("à¤¸à¤¿à¤‚à¤¹à¤² à¤…à¤•à¥à¤·à¤° à¤®à¤¾à¤²à¤¾à¤µ", "hi", "si")
#         self.assertEqual(z, "à·ƒà·’à¶‚à·„à¶½ à¶…à¶šà·Šà·‚à¶» à¶¸à·à¶½à·à·€")
#         t = UnicodeIndicTransliterator.transliterate("à®¤à®®à®¿à®´à¯ à®…à®°à®¿à®šà¯à®šà¯à®µà®Ÿà®¿", "ta", "hi")
#         self.assertEqual(t, "à¤¤à¤®à¤¿à¤´à¥ à¤…à¤°à¤¿à¤šà¥à¤šà¥à¤µà¤Ÿà¤¿")
#         h = UnicodeIndicTransliterator.transliterate("à¤¤à¤®à¤¿à¤´à¥ à¤…à¤°à¤¿à¤šà¥à¤šà¥à¤µà¤Ÿà¤¿", "hi", "ta")
#         self.assertEqual(h, "à®¤à®®à®¿à®´à¯ à®…à®°à®¿à®šà¯à®šà¯à®µà®Ÿà®¿")
#
#     def test_Romanization(self):
#         x = ItransTransliterator.to_itrans("à¤°à¤¾à¤œà¤¸à¥à¤¥à¤¾à¤¨", "hi")
#         self.assertTrue(x == "rAjasthAna" or x == "raajasthaana")
#         x = ItransTransliterator.to_itrans("à¤°à¤¾à¤œà¤¸à¥à¤¥à¤¾à¤¨", "asdasd")
#         self.assertEqual(x, "à¤°à¤¾à¤œà¤¸à¥à¤¥à¤¾à¤¨")
#         ml = ItransTransliterator.to_itrans("à´®à´²", "ml")
#         self.assertEqual(ml, "mala")
#
#     def test_SinhalaDevanagariTransliterator(self):
#         sin = sdt.devanagari_to_sinhala("à¤°à¤¾à¤œà¤¸à¥à¤¥à¤¾à¤¨")
#         self.assertEqual(sin, "à¶»à·à¶¢à·ƒà·Šà¶®à·à¶±")
#         dev = sdt.sinhala_to_devanagari("à¶»à·à¶¢à·ƒà·Šà¶®à·à¶±")
#         self.assertEqual(dev, "à¤°à¤¾à¤œà¤¸à¥à¤¥à¤¾à¤¨")
#
#
# class TestScriptInformation(unittest.TestCase):
#     def test_IsVowel(self):
#         self.assertFalse(is_vowel("à¤•", "hi"))
#         self.assertTrue(is_vowel("à¤…", "hi"))
#
#     def test_IsConsonant(self):
#         self.assertTrue(is_consonant("à¤•", "hi"))
#         self.assertFalse(is_consonant("à¤…", "hi"))
#
#     def test_IsVelar(self):
#         self.assertTrue(is_velar("à¤•", "hi"))
#         self.assertFalse(is_velar("à¤…", "hi"))
#
#     def test_IsPalatal(self):
#         self.assertTrue(is_palatal("à¤š", "hi"))
#         self.assertFalse(is_palatal("à¤¤", "hi"))
#
#     def test_IsAspirated(self):
#         self.assertTrue(is_aspirated("à¤›", "hi"))
#         self.assertFalse(is_aspirated("à¤•", "hi"))
#
#     def test_IsUnvoiced(self):
#         self.assertTrue(is_unvoiced("à¤Ÿ", "hi"))
#         self.assertFalse(is_unvoiced("à¤—", "hi"))
#
#     def test_IsNasal(self):
#         self.assertTrue(is_nasal("à¤£", "hi"))
#         self.assertFalse(is_nasal("à¤¡", "hi"))
#
#     def test_IsVowelSign(self):
#         self.assertTrue(is_vowel_sign("à¤¾", "hi"))
#
#     def test_IsNukta(self):
#         self.assertTrue(is_nukta("à¤¼", "hi"))
#
#     def test_IsAum(self):
#         self.assertTrue(is_aum("à¥", "hi"))
#
#     def test_IsHalanta(self):
#         self.assertTrue(is_halanta("à¥", "hi"))
#
#     def test_IsRetroflex(self):
#         self.assertTrue(is_retroflex("à¤Ÿ", "hi"))
#
#     def test_IsDental(self):
#         self.assertTrue(is_dental("à¤¤", "hi"))
#
#     def test_IsLabial(self):
#         self.assertTrue(is_labial("à¤ª", "hi"))
#
#     def test_IsVoiced(self):
#         self.assertTrue(is_voiced("à¤—", "hi"))
#
#     def test_IsUnAspirated(self):
#         self.assertTrue(is_unaspirated("à¤œ", "hi"))
#
#     def test_IsFricative(self):
#         self.assertTrue(is_fricative("à¤¶", "hi"))
#
#     def test_IsApproximant(self):
#         self.assertTrue(is_approximant("à¤¯", "hi"))
#
#     def test_IsNumber(self):
#         self.assertTrue(is_number("à¥¨", "hi"))
#
#     def test_offset_to_char(self):
#         self.assertEqual(offset_to_char(0x021, "hi"), "à¤¡")
#
#     def test_in_coordinated_range(self):
#         self.assertTrue(in_coordinated_range(0x6E))
#
#     def test_is_indiclang_char(self):
#         self.assertTrue(is_indiclang_char("à¤•", "hi"))
#
#     def test_swadesh_greek(self):
#         swadesh = Swadesh("gr")
#         first_word = "á¼Î³Ï"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_latin(self):
#         swadesh = Swadesh("la")
#         first_word = "ego"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_tocharianB(self):
#         swadesh = Swadesh("txb")
#         first_word = "Ã±Ã¤Å›"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_old_portuguese(self):
#         swadesh = Swadesh("pt_old")
#         first_word = "eu"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_sanskrit(self):
#         swadesh = Swadesh("sa")
#         first_word = "à¤…à¤¹à¤®à¥"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_hindi(self):
#         swadesh = Swadesh("hi")
#         first_word = "à¤®à¥ˆà¤‚"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_old_english(self):
#         swadesh = Swadesh("eng_old")
#         first_word = "ic, iÄ‹Ä‹, ih"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_old_norse(self):
#         swadesh = Swadesh("old_norse")
#         first_word = "ek"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_arabic(self):
#         swadesh = Swadesh("ar")
#         first_word = "Ø£Ù†Ø§"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#
# class TestRunes(unittest.TestCase):
#     def test_rune_alphabet_name(self):
#         self.assertEqual(runes.RunicAlphabetName.elder_futhark.value, "elder_futhark")
#
#     def test_rune_definition(self):
#         haglaz = runes.Rune(
#             runes.RunicAlphabetName.elder_futhark, "\u16BA", "h", "h", "haglaz"
#         )
#         self.assertEqual(haglaz.form, "ášº")
#
#     def test_runic_transcription_definition(self):
#         inscription = "áš¦á›á›…áš´áš¾á›«á›…áš¢áš´á›«áš´áš¢áš¾á›…áš±á›«áš±á›…á›á›‹á›áš¢á›«á›‹á›á›…á›áš¾á›… á›…áš á›á›á›¦á›«áš¢á›…áš±á›«á›’áš±áš¢áš¦áš¢áš±á›«á›‹á›áš¾"
#         transcription = runes.Transcriber.transcribe(inscription, runes.YOUNGER_FUTHARK)
#         self.assertEqual(
#             transcription, "Ã¾iakná›«auká›«kunará›«raistuá›«stainaá›«aftiRá›«uará›«bruÃ¾urá›«sin"
#         )


if __name__ == "__main__":
    unittest.main()

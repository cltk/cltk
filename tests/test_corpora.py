"""Test ``cltk.corpora``."""

import os
import unittest
from unicodedata import normalize
from unittest.mock import patch

from cltk.corpora.grc.tlg.tlgu import TLGU
from cltk.utils.file_operations import make_cltk_path

# import nltk
#
# from cltk.corpus.greek.alphabet import expand_iota_subscript
# from cltk.corpus.greek.alphabet import filter_non_greek
# from cltk.corpus.greek.beta_to_unicode import Replacer
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_female_authors
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_epithet_index
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_epithets
# from cltk.corpus.greek.tlg.parse_tlg_indices import select_authors_by_epithet
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_epithet_of_author
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_geo_index
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_geographies
# from cltk.corpus.greek.tlg.parse_tlg_indices import select_authors_by_geo
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_geo_of_author
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_lists
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_id_author
# from cltk.corpus.greek.tlg.parse_tlg_indices import select_id_by_name
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_works_by_id
# from cltk.corpus.greek.tlg.parse_tlg_indices import check_id
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_date_author
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_dates
# from cltk.corpus.greek.tlg.parse_tlg_indices import get_date_of_author
# from cltk.corpus.greek.tlg.parse_tlg_indices import _get_epoch
# from cltk.corpus.greek.tlg.parse_tlg_indices import _check_number
# from cltk.corpus.greek.tlg.parse_tlg_indices import _handle_splits
# from cltk.corpus.middle_english.alphabet import normalize_middle_english
# from cltk.corpus.old_norse import runes
# from cltk.corpus.utils.formatter import assemble_phi5_author_filepaths
# from cltk.corpus.utils.formatter import assemble_phi5_works_filepaths
# from cltk.corpus.utils.formatter import assemble_tlg_author_filepaths
# from cltk.corpus.utils.formatter import assemble_tlg_works_filepaths
# from cltk.corpus.utils.formatter import phi5_plaintext_cleanup
# from cltk.corpus.utils.formatter import remove_non_ascii
# from cltk.corpus.utils.formatter import remove_non_latin
# from cltk.corpus.utils.formatter import tonos_oxia_converter
# from cltk.corpus.utils.formatter import tlg_plaintext_cleanup
# from cltk.corpus.utils.formatter import cltk_normalize
# from cltk.corpus.utils.importer import CorpusImporter
# from cltk.corpus.utils.importer import CorpusImportError
# from cltk.corpus.sanskrit.itrans.itrans_transliterator import *
# from cltk.corpus.sanskrit.itrans.unicode_transliterate import *
# from cltk.corpus.sanskrit.itrans.langinfo import *
# from cltk.corpus.sanskrit.itrans.sinhala_transliterator import (
#     SinhalaDevanagariTransliterator as sdt,
# )
# from cltk.corpus.punjabi.numerifier import punToEnglish_number
# from cltk.corpus.punjabi.numerifier import englishToPun_number
# from cltk.corpus.egyptian.transliterate_mdc import mdc_unicode
# from cltk.corpus.aramaic.transliterate import square_to_imperial
# from cltk.corpus.utils.formatter import normalize_fr
# from cltk.corpus.swadesh import Swadesh
# from cltk.corpus.readers import assemble_corpus, get_corpus_reader
# from cltk.corpus.latin.latin_library_corpus_types import (
#     corpus_texts_by_type,
#     corpus_directories_by_type,
# )
# from cltk.utils.matrix_corpus_fun import distinct_words

__license__ = "MIT License. See LICENSE."

# DISTRIBUTED_CORPUS_PATH_REL = get_cltk_data_dir() + "/test_distributed_corpora.yaml"
# DISTRIBUTED_CORPUS_PATH = os.path.expanduser(DISTRIBUTED_CORPUS_PATH_REL)


class TestSequenceFunctions(unittest.TestCase):  # pylint: disable=R0904
    """Class for unittest"""

    @classmethod
    def setUpClass(self):
        pass
        # try:
        #     corpus_importer = CorpusImporter("latin")
        #     corpus_importer.import_corpus("latin_text_latin_library")
        #     corpus_importer.import_corpus("latin_text_perseus")
        #     corpus_importer = CorpusImporter("greek")
        #     corpus_importer.import_corpus("greek_text_perseus")
        #     corpus_importer.import_corpus("greek_text_tesserae")
        #     nltk.download("punkt")
        #     nltk.download("averaged_perceptron_tagger")
        # except:
        #     raise Exception("Failure to download test corpus")

    #
    # def test_greek_betacode_to_unicode(self):
    #     """Test converting Beta Code to Unicode.
    #     Note: assertEqual appears to not be correctly comparing certain
    #     characters (``Œ¨`` and ``ŒØ``, at least).
    #     """
    #     replacer = Replacer()
    #     # Generic test
    #     beta_1 = r"""O(/PWS OU)=N MH\ TAU)TO\ """
    #     unicode_1 = replacer.beta_code(beta_1)
    #     target_1 = "·ΩÖœÄœâœÇ Œø·ΩñŒΩ Œº·Ω¥ œÑŒ±·ΩêœÑ·Ω∏ "
    #     # Test for iota and diaeresis
    #     self.assertEqual(unicode_1, target_1)
    #     beta_2 = r"""*XALDAI+KH\N"""
    #     unicode_2 = replacer.beta_code(beta_2)
    #     target_2 = "ŒßŒ±ŒªŒ¥Œ±œäŒ∫·Ω¥ŒΩ"
    #     self.assertEqual(unicode_2, target_2)
    #     # Test for upsilon and diaeresis
    #     beta_3 = r"""PROU+POTETAGME/NWN"""
    #     unicode_3 = replacer.beta_code(beta_3)
    #     target_3 = "œÄœÅŒøœãœÄŒøœÑŒµœÑŒ±Œ≥ŒºŒ≠ŒΩœâŒΩ"
    #     self.assertEqual(unicode_3, target_3)
    #     # Test for lowercase
    #     beta_4 = r"""proi+sxome/nwn"""
    #     unicode_4 = replacer.beta_code(beta_4)
    #     target_4 = "œÄœÅŒøœäœÉœáŒøŒºŒ≠ŒΩœâŒΩ"
    #     self.assertEqual(unicode_4, target_4)

    def test_tlgu_init(self):
        """Test constructors of TLGU module for check, import, and install."""
        TLGU(interactive=False)
        header_file = make_cltk_path("greek/software/greek_software_tlgu/README.md")
        self.assertTrue(os.path.isfile(header_file))


#     def test_import_greek_software_tlgu(self):
#         """Test instantiating TLGU(). This will download and install
#         the software, if necessary.
#         """
#         corpus_importer = CorpusImporter("greek")
#         corpus_importer.import_corpus("greek_software_tlgu")
#         file_rel = os.path.join(
#             get_cltk_data_dir() + "/greek/software/greek_software_tlgu/README.md"
#         )
#         _file = os.path.expanduser(file_rel)
#         file_exists = os.path.isfile(_file)
#         self.assertTrue(file_exists)
#
#     def test_tlgu_convert(self):
#         """Test TLGU convert. This reads the file
#         ``tlgu_test_text_beta_code.txt``, which mimics a TLG file, and
#         converts it.
#         Note: assertEqual fails on some accented characters ('ŒÆ', 'ŒØ').
#         """
#         in_test = os.path.abspath("cltk/tests/test_nlp/tlgu_test_text_beta_code.txt")
#         out_test = os.path.normpath(get_cltk_data_dir() + "/tlgu_test_text_unicode.txt")
#         tlgu = TLGU(testing=True)
#         tlgu.convert(in_test, out_test)
#         with open(out_test) as out_file:
#             new_text = out_file.read()
#         os.remove(out_test)
#         target = """
# Œ≤ŒªŒªŒøŒΩ Œ¥' ·ºÄŒªŒªŒªŒøœÖœÇ œáŒ±ŒªŒ∫œÅŒµœÉŒπŒΩ ·ºêŒ≥œáŒµ·øÉœÉŒπŒΩ.
# """
#         self.assertEqual(new_text, target)
#
#     def test_tlgu_convert_fail(self):
#         """Test the TLGU to fail when importing a corpus that doesn't exist."""
#         tlgu = TLGU(testing=True)
#         with self.assertRaises(AssertionError):
#             tlgu.convert(
#                 "~/Downloads/corpora/TLG_E/bad_path.txt", "~/Documents/thucydides.txt"
#             )
#
#     def test_tlgu_convert_corpus_fail(self):
#         """Test the TLGU to fail when trying to convert an unsupported corpus."""
#         tlgu = TLGU(testing=True)
#         with self.assertRaises(AssertionError):
#             tlgu.convert_corpus(corpus="bad_corpus")
#
#     def test_tlg_plaintext_cleanup(self):
#         """Test post-TLGU cleanup of text of Greek TLG text."""
#         dirty = """{ŒëŒòŒóŒùŒëŒôŒüŒ• ŒùŒëŒ•ŒöŒ°ŒëŒ§ŒôŒ§ŒüŒ• ŒîŒïŒôŒ†ŒùŒüŒ£ŒüŒ¶ŒôŒ£Œ§Œ©Œù} LATIN ·ºàŒ∏ŒÆŒΩŒ±ŒπŒøœÇ (Œº·Ω≤ŒΩ) ·ΩÅ œÑ·øÜœÇ 999 Œ≤ŒØŒ≤ŒªŒøœÖ ‚å©œÄŒ±œÑŒÆœÅ‚å™: œÄŒøŒπŒµ·øñœÑŒ±Œπ Œ¥·Ω≤ œÑ·Ω∏ŒΩ ŒªœåŒ≥ŒøŒΩ œÄœÅ·Ω∏œÇ Œ§ŒπŒºŒøŒ∫œÅŒ¨œÑŒ∑ŒΩ."""  # pylint: disable=line-too-long
#         clean = tlg_plaintext_cleanup(dirty, rm_punctuation=True, rm_periods=False)
#         target = " ·ºàŒ∏ŒÆŒΩŒ±ŒπŒøœÇ Œº·Ω≤ŒΩ ·ΩÅ œÑ·øÜœÇ Œ≤ŒØŒ≤ŒªŒøœÖ œÄŒ±œÑŒÆœÅ œÄŒøŒπŒµ·øñœÑŒ±Œπ Œ¥·Ω≤ œÑ·Ω∏ŒΩ ŒªœåŒ≥ŒøŒΩ œÄœÅ·Ω∏œÇ Œ§ŒπŒºŒøŒ∫œÅŒ¨œÑŒ∑ŒΩ."
#         self.assertEqual(clean, target)
#
#     def test_tlg_plaintext_cleanup_rm_periods(self):
#         """Test post-TLGU cleanup of text of Greek TLG text."""
#         dirty = """{ŒëŒòŒóŒùŒëŒôŒüŒ• ŒùŒëŒ•ŒöŒ°ŒëŒ§ŒôŒ§ŒüŒ• ŒîŒïŒôŒ†ŒùŒüŒ£ŒüŒ¶ŒôŒ£Œ§Œ©Œù} LATIN ·ºàŒ∏ŒÆŒΩŒ±ŒπŒøœÇ (Œº·Ω≤ŒΩ) ·ΩÅ œÑ·øÜœÇ 999 Œ≤ŒØŒ≤ŒªŒøœÖ ‚å©œÄŒ±œÑŒÆœÅ‚å™: œÄŒøŒπŒµ·øñœÑŒ±Œπ Œ¥·Ω≤ œÑ·Ω∏ŒΩ ŒªœåŒ≥ŒøŒΩ œÄœÅ·Ω∏œÇ Œ§ŒπŒºŒøŒ∫œÅŒ¨œÑŒ∑ŒΩ."""  # pylint: disable=line-too-long
#         clean = tlg_plaintext_cleanup(dirty, rm_punctuation=True, rm_periods=True)
#         target = " ·ºàŒ∏ŒÆŒΩŒ±ŒπŒøœÇ Œº·Ω≤ŒΩ ·ΩÅ œÑ·øÜœÇ Œ≤ŒØŒ≤ŒªŒøœÖ œÄŒ±œÑŒÆœÅ œÄŒøŒπŒµ·øñœÑŒ±Œπ Œ¥·Ω≤ œÑ·Ω∏ŒΩ ŒªœåŒ≥ŒøŒΩ œÄœÅ·Ω∏œÇ Œ§ŒπŒºŒøŒ∫œÅŒ¨œÑŒ∑ŒΩ"
#         self.assertEqual(clean, target)
#
#     def test_phi5_plaintext_cleanup(self):
#         """Test post-TLGU cleanup of text of Latin PHI5 text."""
#         dirty = """        {ODYSSIA}
#         {Liber I}
# Virum √°ge 999 mihi, Camena, (insece) versutum.
# Pater noster, Saturni filie . . .
# Mea puera, quid verbi ex tuo ore supera fugit?
# argenteo polubro, aureo eclutro. """
#         clean = phi5_plaintext_cleanup(dirty, rm_punctuation=True, rm_periods=False)
#         target = " Virum √°ge mihi Camena versutum. Pater noster Saturni filie . . . Mea puera quid verbi ex tuo ore supera fugit argenteo polubro aureo eclutro. "  # pylint: disable=line-too-long
#         self.assertEqual(clean, target)
#
#     def test_phi5_plaintext_cleanup_rm_periods(self):
#         """Test post-TLGU cleanup of text of Latin PHI5 text."""
#         dirty = """        {ODYSSIA}
#         {Liber I}
# Virum √°ge 999 mihi, Camena, (insece) versutum.
# Pater noster, Saturni filie . . .
# Mea puera, quid verbi ex tuo ore supera fugit?
# argenteo polubro, aureo eclutro. """
#         clean = phi5_plaintext_cleanup(dirty, rm_punctuation=True, rm_periods=True)
#         target = " Virum √°ge mihi Camena versutum Pater noster Saturni filie Mea puera quid verbi ex tuo ore supera fugit argenteo polubro aureo eclutro "  # pylint: disable=line-too-long
#         self.assertEqual(clean, target)
#
#     def test_phi5_plaintext_cleanup_rm_periods_bytes(self):
#         """Test post-TLGU cleanup of text of Latin PHI5 text."""
#         dirty = "\xcc\x81 Virum √°ge 999 mihi."
#         clean = phi5_plaintext_cleanup(dirty, rm_punctuation=True, rm_periods=True)
#         target = "√å¬Å Virum √°ge mihi"
#         self.assertEqual(clean, target)
#
#     def test_cltk_normalize_compatible(self):
#         """Test Normalizing Text with compatibility True"""
#         s1 = "cafeÃÅ"
#         s2 = "cafe\u0301"
#         normalized_text = cltk_normalize(s1, compatibility=True)
#         target = normalize("NFKC", s2)
#         self.assertEqual(normalized_text, target)
#
#     def test_cltk_normalize_noncompatible(self):
#         """Test Normalizing Text with compatibility False"""
#         s1 = "cafeÃÅ"
#         s2 = "cafe\u0301"
#         normalized_text = cltk_normalize(s1, compatibility=False)
#         target = normalize("NFC", s2)
#         self.assertEqual(normalized_text, target)
#
#     def test_assemble_tlg_author(self):
#         """Test building absolute filepaths from TLG index."""
#         paths = assemble_tlg_author_filepaths()
#         self.assertEqual(len(paths), 1823)
#
#     def test_assemble_phi5_author(self):
#         """Test building absolute filepaths from TLG index."""
#         paths = assemble_phi5_author_filepaths()
#         self.assertEqual(len(paths), 362)
#
#     def test_assemble_tlg_works(self):
#         """"Test building absolute filepaths from TLG works index."""
#         paths = assemble_tlg_works_filepaths()
#         self.assertEqual(len(paths), 6625)
#
#     def test_assemble_phi5_works(self):
#         """"Test building absolute filepaths from PHI5 works index."""
#         paths = assemble_phi5_works_filepaths()
#         self.assertEqual(len(paths), 836)
#
#     def test_corpora_import_list_greek(self):
#         """Test listing of available corpora."""
#         corpus_importer = CorpusImporter("greek")
#         available_corpora = corpus_importer.list_corpora
#         self.assertTrue(available_corpora)
#
#     def test_corpora_import_list_latin(self):
#         """Test listing of available corpora."""
#         corpus_importer = CorpusImporter("latin")
#         available_corpora = corpus_importer.list_corpora
#         self.assertTrue(available_corpora)
#
#     def test_tonos_oxia_converter(self):
#         """Test function converting tonos to oxia accent."""
#         char_tonos = "Œ¨"  # with tonos, for Modern Greek
#         char_oxia = "·Ω±"  # with oxia, for Ancient Greek
#         corrected = tonos_oxia_converter(char_tonos)
#         self.assertEqual(char_oxia, corrected)
#
#     def test_tonos_oxia_converter_reverse(self):
#         """Test function converting tonos to oxia accent."""
#         char_tonos = "Œ¨"  # with tonos, for Modern Greek
#         char_oxia = "Œ¨"  # with oxia, for Ancient Greek
#         corrected = tonos_oxia_converter(char_oxia, reverse=True)
#         self.assertEqual(char_tonos, corrected)
#
#     def test_remove_non_ascii(self):
#         """Test removing all non-ascii characters from a string."""
#         non_ascii_str = "Ascii and some non-ascii: Œ∏ŒµŒø·Ω∫œÇ Œº·Ω≤ŒΩ Œ±·º∞œÑ·ø∂ œÑ·ø∂ŒΩŒ¥·æΩ ·ºÄœÄŒ±ŒªŒªŒ±Œ≥·Ω¥ŒΩ"  # pylint: disable=line-too-long
#         ascii_str = remove_non_ascii(non_ascii_str)
#         valid = "Ascii and some non-ascii:     "
#         self.assertEqual(ascii_str, valid)
#
#     def test_remove_non_latin(self):
#         """Test removing all non-Latin characters from a string."""
#         latin_str = "(1) Dices ·ºêœÉœÑŒπŒΩ ·ºêŒºœåœÇ pulchrum esse inimicos ulcisci."  # pylint: disable=line-too-long
#         non_latin_str = remove_non_latin(latin_str)
#         valid = " Dices   pulchrum esse inimicos ulcisci"
#         self.assertEqual(non_latin_str, valid)
#
#     def test_remove_non_latin_opt(self):
#         """Test removing all non-Latin characters from a string, with
#         `also_keep` parameter.
#         """
#         latin_str = "(1) Dices ·ºêœÉœÑŒπŒΩ ·ºêŒºœåœÇ pulchrum esse inimicos ulcisci."  # pylint: disable=line-too-long
#         non_latin_str = remove_non_latin(latin_str, also_keep=[".", ","])
#         valid = " Dices   pulchrum esse inimicos ulcisci."
#         self.assertEqual(non_latin_str, valid)
#
#     def test_latin_library_reader_missing_corpus(self):
#         """
#         Needs to precede (for now) the next two tests which load the corpus
#         Provided by Patrick Burns
#         """
#         corpus_importer = CorpusImporter("latin")
#         # corpus_importer.import_corpus('latin_text_latin_library')
#         corpus_importer.import_corpus("latin_models_cltk")
#
#         def _import():
#             with patch("builtins.input", return_value="n"):
#                 from cltk.corpus.readers import latinlibrary
#
#                 self.assertRaises(OSError, _import)
#
#     def test_import_lat_text_lat_lib(self):
#         """Test cloning the Latin Library text corpus."""
#         corpus_importer = CorpusImporter("latin")
#         corpus_importer.import_corpus("latin_text_latin_library")
#         file_rel = os.path.join(
#             get_cltk_data_dir() + "/latin/text/latin_text_latin_library/README.md"
#         )
#         _file = os.path.expanduser(file_rel)
#         file_exists = os.path.isfile(_file)
#         self.assertTrue(file_exists)
#
#     def test_import_latin_library_corpus_reader(self):
#         """Test the Latin Library corpus reader."""
#         corpus_importer = CorpusImporter("latin")
#         corpus_importer.import_corpus("latin_text_latin_library")
#         reader = get_corpus_reader(
#             language="latin", corpus_name="latin_text_latin_library"
#         )
#         ALL_FILE_IDS = list(reader.fileids())
#         self.assertTrue(len(ALL_FILE_IDS) > 2100)
#
#     def test_json_corpus_reader(self):
#         """Test filtered corpus sents method."""
#         reader = get_corpus_reader(language="latin", corpus_name="latin_text_perseus")
#         # this has simple sections
#         reader._fileids = ["cicero__on-behalf-of-aulus-caecina__latin.json"]
#         self.assertTrue(len(list(reader.paras())) >= 1)
#         self.assertTrue(len(list(reader.sents())) > 400)
#         self.assertTrue(len(list(reader.words())) > 12000)
#         reader = get_corpus_reader(language="latin", corpus_name="latin_text_perseus")
#         # this example has subsections
#         reader._fileids = ["ausonius-decimus-magnus__eclogarum-liber__latin.json"]
#         self.assertTrue(len(list(reader.docs())) == 1)
#         self.assertTrue(len(list(reader.paras())) >= 1)
#         self.assertTrue(len(list(reader.sents())) > 50)
#         self.assertTrue(len(list(reader.words())) > 2750)
#         # reader = get_corpus_reader(corpus_name='greek_text_perseus', language='greek')
#         # reader._fileids = ['plato__apology__grc.json']
#         # self.assertTrue(len(list(reader.docs())) == 1)
#         # self.assertTrue(len(list(reader.paras())) > 1)
#         # self.assertTrue(len(list(reader.sents())) > 260)
#         # self.assertTrue(len(list(reader.words())) > 9800)
#
#     def test_tesserae_corpus_reader(self):
#         """Test Tesserae corpus methods."""
#         # Update when corpus is add to CLTK
#         reader = get_corpus_reader(language="greek", corpus_name="greek_text_tesserae")
#         sample = reader.fileids()[0]
#         self.assertTrue(len(list(reader.docs(sample))) >= 1)
#         self.assertTrue(len(list(reader.texts(sample))) >= 1)
#         self.assertTrue(len(list(reader.paras(sample))) >= 1)
#         self.assertTrue(len(list(reader.sents(sample))) >= 1)
#         self.assertTrue(len(list(reader.words(sample))) >= 1)
#         self.assertTrue(len(list(reader.lines(sample))) >= 1)
#         self.assertTrue(reader.describe())
#         self.assertTrue(len(list(reader.pos_tokenize(sample))) >= 1)
#
#     def test_json_corpus_reader_sizes(self):
#         """Test filtered corpus sizes method."""
#         reader = get_corpus_reader(language="latin", corpus_name="latin_text_perseus")
#         self.assertTrue(len(list(reader.sizes())) > 290)
#
#     def test_import_latin_models_cltk(self):
#         """Test cloning the CLTK Latin models."""
#         corpus_importer = CorpusImporter("latin")
#         corpus_importer.import_corpus("latin_models_cltk")
#         file_rel = os.path.join(
#             get_cltk_data_dir() + "/latin/model/latin_models_cltk/README.md"
#         )
#         _file = os.path.expanduser(file_rel)
#         file_exists = os.path.isfile(_file)
#         self.assertTrue(file_exists)
#
#     def test_import_greek_models_cltk(self):
#         """Test pull (not clone) the CLTK Greek models. Import was run in
#         ``setUp()``.
#         """
#         corpus_importer = CorpusImporter("greek")
#         corpus_importer.import_corpus("greek_models_cltk")
#         file_rel = os.path.join(
#             get_cltk_data_dir() + "/greek/model/greek_models_cltk/README.md"
#         )
#         _file = os.path.expanduser(file_rel)
#         file_exists = os.path.isfile(_file)
#         self.assertTrue(file_exists)
#
#     def test_show_corpora_bad_lang(self):
#         """Test failure of importer upon selecting unsupported language."""
#         with self.assertRaises(CorpusImportError):
#             CorpusImporter("bad_lang")
#
#     def test_import_nonexistant_corpus(self):
#         """Test that creating a CorpusImporter for a non existent lang
#            fails smoothly
#         """
#         with self.assertRaises(CorpusImportError):
#             corpus_importer = CorpusImporter("greek")
#             corpus_importer.import_corpus("euclids_book_of_recipes")
#
#     def test_import_latin_text_antique_digiliblt(self):
#         """Test cloning the Antique Latin from digilibLT."""
#         corpus_importer = CorpusImporter("latin")
#         corpus_importer.import_corpus("latin_text_antique_digiliblt")
#         file_rel = os.path.join(
#             get_cltk_data_dir() + "/latin/text/latin_text_antique_digiliblt/README.md"
#         )
#         _file = os.path.expanduser(file_rel)
#         file_exists = os.path.isfile(_file)
#         self.assertTrue(file_exists)
#
#     def test_get_female_authors(self):
#         """Test function to parse TLG female authors list."""
#         authors = get_female_authors()
#         authors = sorted(authors)[:3]
#         self.assertEqual(authors, ["0009", "0051", "0054"])
#
#     def test_get_epithet_index(self):
#         """Test get_epithet_index()."""
#         ind = get_epithet_index()
#         self.assertEqual(type(ind), dict)
#
#     def test_get_epithets(self):
#         """Test get_epithets()."""
#         epithets = get_epithets()
#         self.assertEqual(epithets[:2], ["Alchemistae", "Apologetici"])
#
#     def test_select_authors_by_epithet(self):
#         """Test select_authors_by_epithet()."""
#         authors = select_authors_by_epithet("Apologetici")
#         self.assertEqual(len(authors), 9)
#
#     def test_get_epithet_of_author(self):
#         """Test get_epithet_of_author()."""
#         epithet = get_epithet_of_author("0016")
#         self.assertEqual(epithet, "Historici/-ae")
#
#     def test_get_geo_index(self):
#         """Test get_geo_index()."""
#         index = get_geo_index()
#         self.assertEqual(type(index), dict)
#
#     def test_get_geographies(self):
#         """Test get_geographies()."""
#         geos = get_geographies()
#         self.assertEqual(type(geos), list)
#
#     def test_select_authors_by_geo(self):
#         """Test select_authors_by_geo()."""
#         authors = select_authors_by_geo("Athenae")
#         self.assertEqual(len(authors), 113)
#
#     def test_get_geo_of_author(self):
#         """Test get_geo_of_author()."""
#         geo = get_geo_of_author("0008")
#         self.assertEqual(geo, "Naucratis")
#
#     def test_get_lists(self):
#         """Test get_lists()."""
#         index = get_lists()
#         self.assertEqual(type(index), dict)
#
#     def test_get_id_author(self):
#         """Test get_id_author()."""
#         self.assertEqual(type(get_id_author()), dict)
#
#     def test_select_id_by_name(self):
#         """Test select_id_by_name()."""
#         matches = select_id_by_name("hom")
#         self.assertEqual(len(matches), 11)
#
#     def test_get_works_by_id(self):
#         """Test get_works_by_id()."""
#         works = get_works_by_id("0007")
#         self.assertEqual(len(works), 147)
#
#     def test_check_id(self):
#         """Test check_id"""
#         author = check_id("0557")
#         valid = "Epictetus Phil."
#         self.assertEqual(author, valid)
#
#     # #! Figure out why this test stopped working (actual function runs fine)
#     # def test_get_date_author(self):
#     #     """Test get_date_author()."""
#     #     dates = get_date_author()
#     #     self.assertEqual(type(dates), dict)
#
#     # #! Figure out why this test stopped working (actual function runs fine)
#     # def test_get_dates(self):
#     #     """Test get_dates()."""
#     #     dates = get_dates()
#     #     self.assertEqual(type(dates), list)
#     #     self.assertEqual(len(dates), 183)
#
#     # #! Figure out why this test stopped working (actual function runs fine)
#     # def test_get_date_of_author(self):
#     #     """Test get_date_of_author()."""
#     #     self.assertEqual(get_date_of_author('1747'), '1 B.C./A.D. 1')
#     #     self.assertEqual(get_date_of_author('1143'), '2-1 B.C.')
#     #     self.assertEqual(get_date_of_author('0295'), 'Varia')
#     #     self.assertEqual(get_date_of_author('4304'), 'a. A.D. 10')
#     #     self.assertIsNone(get_date_of_author('123456'))
#
#     def test_get_epoch(self):
#         """Test _get_epoch()."""
#         self.assertEqual(_get_epoch("A.D. 9-10"), "ad")
#         self.assertEqual(_get_epoch("p. A.D. 2"), "ad")
#         self.assertIsNone(_get_epoch("a. A.D. 2"))
#         self.assertEqual(_get_epoch("3 B.C."), "bc")
#         self.assertIsNone(_get_epoch("p. 7 B.C."))
#         self.assertEqual(_get_epoch("a. 1 B.C."), "bc")
#         self.assertEqual(_get_epoch("a. 1 B.C.?"), "bc")
#
#     def test_check_number(self):
#         """Test _check_number()."""
#         self.assertTrue(_check_number("5"))
#         self.assertTrue(_check_number("5?"))
#         self.assertFalse(_check_number("A.D. 5"))
#         self.assertFalse(_check_number("A.D. 5?"))
#         self.assertFalse(_check_number("p. 4 B.C."))
#
#     def test_handle_splits(self):
#         """Test _handle_splits()."""
#         _dict = {
#             "start_raw": "A.D. 9",
#             "start_epoch": "ad",
#             "stop_epoch": "ad",
#             "stop_raw": "A.D. 10",
#         }
#         self.assertEqual(_handle_splits("A.D. 9-10"), _dict)
#         _dict = {
#             "start_raw": "A.D. 1?",
#             "start_epoch": "ad",
#             "stop_epoch": "ad",
#             "stop_raw": "A.D. 6",
#         }
#         self.assertEqual(_handle_splits("A.D. 1?-6"), _dict)
#         _dict = {
#             "stop_raw": "p. A.D. 2",
#             "start_raw": "a. 4 B.C.",
#             "stop_epoch": "ad",
#             "start_epoch": "bc",
#         }
#         self.assertEqual(_handle_splits("a. 4 B.C.-p. A.D. 2"), _dict)
#         _dict = {
#             "stop_raw": "A.D. 2?",
#             "start_raw": "A.D. 2?",
#             "stop_epoch": "ad",
#             "start_epoch": "ad",
#         }
#         self.assertEqual(_handle_splits("A.D. 2?"), _dict)
#         _dict = {
#             "stop_raw": "1 B.C.?",
#             "start_raw": "2 B.C.?",
#             "stop_epoch": "bc",
#             "start_epoch": "bc",
#         }
#         self.assertEqual(_handle_splits("2/1 B.C.?"), _dict)
#
#     def test_punjabi_to_english_number_conversion(self):
#         str_test = "‡©ß‡©®‡©©‡©™‡©´‡©¨‡©≠‡©Æ‡©Ø‡©¶"
#         self.assertEqual(1234567890, punToEnglish_number(str_test))
#
#     def test_englishToPun_number(self):
#         str_test = "‡©ß‡©®‡©©‡©™‡©´‡©¨‡©≠‡©Æ‡©Ø‡©¶"
#         self.assertEqual(str_test, englishToPun_number(1234567890))
#
#     def test_english_to_punjabi_number_conversion(self):
#         """Test English to Punjabi number conversion."""
#         str_test = "‡©ß‡©®‡©©‡©™‡©´‡©¨‡©≠‡©Æ‡©Ø‡©¶"
#         self.assertEqual(str_test, englishToPun_number(1234567890))
#
#     def make_distributed_corpora_testing_file(self):
#         """Setup for some cloning tests, make file at
#         get_cltk_data_dir() + '/test_distributed_corpora.yaml'.
#         """
#         # ! Don't format this literal string, must be YAML-ish
#         yaml_str_to_write = """example_distributed_latin_corpus:
#         git_remote: git@github.com:kylepjohnson/latin_corpus_newton_example.git
#         language: latin
#         type: text
#
# example_distributed_fake_language_corpus:
#         origin: git@github.com:kylepjohnson/doesntexistyet.git
#         language: fake_language
#         type: treebank
#     """
#         cltk_data_dir = get_cltk_data_dir()
#         if not os.path.isdir(cltk_data_dir):
#             os.mkdir(cltk_data_dir)
#         with open(DISTRIBUTED_CORPUS_PATH, "w") as file_open:
#             file_open.write(yaml_str_to_write)
#
#     def remove_distributed_corpora_testing_file(self):
#         """Remove ~/cltk_data/test_distributed_corpora.yaml."""
#         os.remove(DISTRIBUTED_CORPUS_PATH)
#
#     def test_corpus_importer_variables_no_user_but_in_core(self):
#         """Test function which checks for presence of
#         ~/cltk_data/distributed_corpora.yaml. Look for a language
#         not in core repos but not in user-defined.
#         """
#         self.make_distributed_corpora_testing_file()
#         corpus_importer = CorpusImporter("sanskrit", testing=True)
#         self.assertIn("sanskrit_models_cltk", corpus_importer.list_corpora)
#         self.remove_distributed_corpora_testing_file()
#
#     def test_corpus_importer_variables_user_but_not_core(self):
#         """Test function which checks for presence of
#         `~/cltk_data/distributed_corpora.yaml`. Look for a language
#         not in the core but in the user's custom file.
#         """
#         self.make_distributed_corpora_testing_file()
#         corpus_importer = CorpusImporter("fake_language", testing=True)
#         corpus_name = corpus_importer.list_corpora
#         target_name = "example_distributed_fake_language_corpus"
#         self.assertEqual(corpus_name[0], target_name)
#         self.remove_distributed_corpora_testing_file()
#
#     def test_corpus_importer_variables_no_user_but_yes_core(self):
#         """Test function which checks for presence of
#         `~/cltk_data/distributed_corpora.yaml`. Look for a language
#         in the core but not in the user's custom file.
#         """
#         self.make_distributed_corpora_testing_file()
#         corpus_importer = CorpusImporter("pali", testing=True)
#         corpora = corpus_importer.list_corpora
#         self.assertIn("pali_text_ptr_tipitaka", corpora)
#         self.remove_distributed_corpora_testing_file()
#
#     def test_corpus_importer_variables_no_user_no_core(self):
#         """Test function which checks for presence of
#         `~/cltk_data/distributed_corpora.yaml`. Look for a language
#         neither in the core or in the user's custom file.
#         """
#         self.make_distributed_corpora_testing_file()
#         with self.assertRaises(CorpusImportError):
#             CorpusImporter("fake_language_nowhere")
#         self.remove_distributed_corpora_testing_file()
#
#     #
#     # def test_import_punjabi_punjabi_text_gurban(self):
#     #     pun_import = CorpusImporter('punjabi')
#     #     corpora_list = pun_import.list_corpora
#     #     self.assertTrue('punjabi_text_gurban' in corpora_list)
#     #     pun_import.import_corpus('punjabi_text_gurban')
#     #     file_path = os.path.join(get_cltk_data_dir() + '/punjabi/text/punjabi_text_gurban/README.md')
#     #     _file = os.path.expanduser(file_path)
#     #     self.assertTrue(os.path.isfile(_file))
#     #
#     # Ancient Egyptian Stuff -----------------------------
#
#     def test_egyptian_transliterate_mdc_to_unicode_q_kopf_True(self):
#         """
#         test to transliterate mdc to unicode
#         for ancient egyptian texts.
#         q_kopf option True
#         """
#         #
#         mdc_string = """ink Smsw Sms nb=f bAk n ipt nswt
#         irt pat wrt <Hswt> Hmt [nswt] snwsrt m Xnm-swt
#         sAt nswt imn-m-HAt m
#         qA-nfrw nfrw nbt imAx"""
#         #
#         test_result_string = mdc_unicode(mdc_string)
#         #
#         comparison_string = """i“Ünk ≈°msw ≈°ms nb‚∏óf bÍú£k n i“Üpt nswt
#         i“Ürt pÍú•t wrt ‚å©·∏•swt‚å™ ·∏•mt [nswt] snwsrt m ·∫ñnm-swt
#         sÍú£t nswt i“Ümn-m-·∏•Íú£t m
#         qÍú£-nfrw nfrw nbt i“ÜmÍú£·∏´"""
#         #
#         self.assertEqual(test_result_string, comparison_string)
#
#     def test_egyptian_transliterate_mdc_to_unicode_q_kopf_False(self):
#         """
#         test to transliterate mdc to unicode
#         for ancient egyptian texts.
#         q_kopf option False
#         """
#         #
#         mdc_string = """ink Smsw Sms nb=f bAk n ipt nswt
#         irt pat wrt <Hswt> Hmt [nswt] snwsrt m Xnm-swt
#         sAt nswt imn-m-HAt m
#         qA-nfrw nfrw nbt imAx"""
#         #
#         test_result_string = mdc_unicode(mdc_string, q_kopf=False)
#         #
#         comparison_string = """i“Ünk ≈°msw ≈°ms nb‚∏óf bÍú£k n i“Üpt nswt
#         i“Ürt pÍú•t wrt ‚å©·∏•swt‚å™ ·∏•mt [nswt] snwsrt m ·∫ñnm-swt
#         sÍú£t nswt i“Ümn-m-·∏•Íú£t m
#         ·∏≥Íú£-nfrw nfrw nbt i“ÜmÍú£·∏´"""
#         #
#         self.assertEqual(test_result_string, comparison_string)
#
#     def test_square_to_imperial_(self):
#         "test square_to_imperial function"
#         square_script = "◊§◊ì◊ô ◊ë◊® ◊ì◊í[◊†]◊û◊ú◊ö ◊ú◊ê◊ó◊ê ◊ë◊® ◊ó◊§◊ô◊ï ◊†◊™◊†◊™ ◊ú◊ö"
#         imperial_version = "ê°êê°Éê°â ê°Åê°ì ê°Éê°Ç[ê°ç]ê°åê°ãê°ä ê°ãê°Äê°áê°Ä ê°Åê°ì ê°áê°êê°âê°Ö ê°çê°ïê°çê°ï ê°ãê°ä"
#         result = square_to_imperial(square_script)
#         self.assertEqual(imperial_version, result)
#
#     def test_expand_iota_subscript(self):
#         """Test subscript expander."""
#         unexpanded = "Œµ·º∞ Œ¥·Ω≤ Œ∫Œ±·Ω∂ œÑ·ø∑ ·º°Œ≥ŒµŒºœåŒΩŒπ œÄŒπœÉœÑŒµœçœÉŒøŒºŒµŒΩ ·ΩÉŒΩ ·ºÇŒΩ Œö·ø¶œÅŒøœÇ Œ¥ŒπŒ¥·ø∑"
#         expanded = expand_iota_subscript(unexpanded)
#         target = "Œµ·º∞ Œ¥·Ω≤ Œ∫Œ±·Ω∂ œÑ·ø∂Œô ·º°Œ≥ŒµŒºœåŒΩŒπ œÄŒπœÉœÑŒµœçœÉŒøŒºŒµŒΩ ·ΩÉŒΩ ·ºÇŒΩ Œö·ø¶œÅŒøœÇ Œ¥ŒπŒ¥·ø∂Œô"
#         self.assertEqual(expanded, target)
#
#     def test_expand_iota_subscript_lower(self):
#         """Test subscript expander."""
#         unexpanded = "Œµ·º∞ Œ¥·Ω≤ Œ∫Œ±·Ω∂ œÑ·ø∑ ·º°Œ≥ŒµŒºœåŒΩŒπ œÄŒπœÉœÑŒµœçœÉŒøŒºŒµŒΩ ·ΩÉŒΩ ·ºÇŒΩ Œö·ø¶œÅŒøœÇ Œ¥ŒπŒ¥·ø∑"
#         expanded = expand_iota_subscript(unexpanded, lowercase=True)
#         target = "Œµ·º∞ Œ¥·Ω≤ Œ∫Œ±·Ω∂ œÑ·ø∂Œπ ·º°Œ≥ŒµŒºœåŒΩŒπ œÄŒπœÉœÑŒµœçœÉŒøŒºŒµŒΩ ·ΩÉŒΩ ·ºÇŒΩ Œ∫·ø¶œÅŒøœÇ Œ¥ŒπŒ¥·ø∂Œπ"
#         self.assertEqual(expanded, target)
#
#     #
#     def test_filter_non_greek(self):
#         """
#         Test filter non greek characters in a mixed string.
#         """
#         test_input_string = (
#             "[·ºôŒ∫Œ±]œÑ·ΩπŒºŒ±ŒΩŒ¥[œÅŒøœÇ Œë·º∞œÉœá]œÅ·Ω∑œâŒΩŒøœÇ ‚ãÆ ·ºàœÅ[ŒπœÉœÑŒµ·Ω∑Œ¥Œ∑..c5..]"  # PH247029, line 2
#         )
#         comparison_string = "·ºôŒ∫Œ±œÑŒºŒ±ŒΩŒ¥œÅŒøœÇ Œë·º∞œÉœáœÅœâŒΩŒøœÇ  ·ºàœÅŒπœÉœÑŒµŒ¥Œ∑"
#         test_result_string = filter_non_greek(test_input_string)
#         #
#         self.assertEqual(test_result_string, comparison_string)
#
#     def test_normalize(self):
#         """
#         Test french normalizer
#         """
#         text = "viw"
#         normalized = normalize_fr(text)
#         target = ["vieux"]
#         self.assertEqual(normalized, target)
#
#     def test_normalize_middle_english(self):
#         """Tests ME normalizer"""
#         in_test = "'Madame,' quod he, 'reule me As »ù,e ly:k?e√æ best.'"
#         target = "'madame' quod he 'reule me as ye lyketh best'"
#         test = normalize_middle_english(in_test)
#         self.assertEqual(target, test)
#
#
# class TestFilteredCorpus(unittest.TestCase):
#     """Test the Latin Library corpus reader filter"""
#
#     @classmethod
#     def setUpClass(self):
#         try:
#             corpus_importer = CorpusImporter("latin")
#             corpus_importer.import_corpus("latin_models_cltk")
#             corpus_importer.import_corpus("latin_text_latin_library")
#         except:
#             raise Exception("Failure to download test corpus")
#         self.reader = get_corpus_reader(
#             language="latin", corpus_name="latin_text_latin_library"
#         )
#         self.reader._fileids = ["pervig.txt"]
#         # Need a additional instance because tests below change internals #TO-DO Fix
#         self.reader_2 = get_corpus_reader(
#             language="latin", corpus_name="latin_text_latin_library"
#         )
#         self.reader_3 = get_corpus_reader(
#             language="latin", corpus_name="latin_text_latin_library"
#         )
#         self.reader_4 = get_corpus_reader(
#             language="latin", corpus_name="latin_text_latin_library"
#         )
#
#     def test_import_latin_library_corpus_filter_by_file(self):
#         """Test the Latin Library corpus reader filter by files."""
#         filtered_reader = assemble_corpus(
#             self.reader_2, types_requested=["old"], type_files=corpus_texts_by_type
#         )
#         self.assertTrue(len(list(filtered_reader.fileids())) > 0)
#
#     def test_import_latin_library_corpus_filter_by_dir(self):
#         """Test the Latin Library corpus reader filter by directories."""
#         filtered_reader = assemble_corpus(
#             self.reader_3, types_requested=["old"], type_dirs=corpus_directories_by_type
#         )
#         self.assertTrue(len(list(filtered_reader.fileids())) > 0)
#
#     def test_import_latin_library_corpus_filter_by_file_and_dir(self):
#         """Test the Latin Library corpus reader filter by directories."""
#         filtered_reader = assemble_corpus(
#             self.reader_4,
#             types_requested=["old"],
#             type_dirs=corpus_directories_by_type,
#             type_files=corpus_texts_by_type,
#         )
#         self.assertTrue(len(list(filtered_reader.fileids())) > 0)
#
#     def test_filtered_corpus_reader_sents(self):
#         """Test filtered corpus sents method."""
#         sents = self.reader.sents()
#         uniq_words = distinct_words(sents)
#         # Curious‚Äîwhy the original test checked for two different words?
#         if "Library" in uniq_words:
#             self.fail("Filtered word present!")
#         # You can check for uniq_words because it implies that sents had content
#         self.assertTrue(uniq_words)
#
#     def test_filtered_corpus_reader_paras(self):
#         """Test filtered corpus paras method."""
#         paras = self.reader.paras()
#         sents = [sent for para in paras for sent in para]
#         uniq_words = distinct_words(sents)
#         if "Library" in uniq_words:
#             self.fail("Filtered word present!")
#         self.assertTrue(uniq_words)
#
#     def test_filtered_corpus_reader_words(self):
#         """Test filtered corpus words method."""
#         words = self.reader.words()
#         uniq_words = distinct_words(words)
#         if "Library" in uniq_words:
#             self.fail("Filtered word present!")
#         self.assertTrue(uniq_words)
#
#     def test_filtered_corpus_reader_docs(self):
#         """Test filtered corpus docs method."""
#         docs = list(self.reader.docs())
#         uniq_words = distinct_words(docs)
#         if "Library" in uniq_words:
#             self.fail("Filtered word present!")
#         self.assertTrue(len(docs) > 0)
#         problem_files = [
#             "caesar/bc3.txt",
#             "hymni.txt",
#             "varro.frag.txt",
#             "varro.ll10.txt",
#             "varro.ll5.txt",
#             "varro.ll6.txt",
#             "varro.ll7.txt",
#             "varro.ll8.txt",
#             "varro.ll9.txt",
#         ]
#         for filename in problem_files:
#             doc = list(self.reader.docs([filename]))
#             assert doc
#             assert len(doc[0]) > 100
#
#     def test_filtered_corpus_reader_sizes(self):
#         """Test filtered corpus sizes method."""
#         self.assertTrue(len(list(self.reader.sizes())) > 0)
#
#
# class TestUnicode(unittest.TestCase):
#     "Test py23char"
#
#     def test_py23char(self):
#         self.assertEqual(py23char(0x92D), "‡§≠")
#         self.assertFalse(py23char(0x93D) == "‡§≠")
#
#
# class TestTransliteration(unittest.TestCase):
#     "Test the transliteration in corpus.sanskrit"
#
#     def test_Indicization(
#         self,
#     ):  # Test ItransTransliterator - Convert from Itrans to Devanagari
#         x = ItransTransliterator.from_itrans("pitL^In", "hi")
#         y = ItransTransliterator.from_itrans("yogazcittavRttinirodhaH", "hi")
#         z = ItransTransliterator.from_itrans("yogazcittavRttinirodhaH", "badVar")
#         self.assertEqual(x, "‡§™‡§ø‡§§‡•£‡§®‡•ç")
#         self.assertEqual(y, "‡§Ø‡•ã‡§ó‡§∂‡•ç‡§ö‡§ø‡§§‡•ç‡§§‡§µ‡•ç‡§±‡•ç‡§§‡•ç‡§§‡§ø‡§®‡§ø‡§∞‡•ã‡§ß‡§É")
#         self.assertEqual(z, "yogazcittavRttinirodhaH")
#
#     def test_ScriptConversion(
#         self,
#     ):  # Test UnicodeIndicTransliterator - Convert between various scripts
#         x = UnicodeIndicTransliterator.transliterate("‡§∞‡§æ‡§ú‡§∏‡•ç‡§•‡§æ‡§®", "hi", "pa")
#         self.assertEqual(x, "‡®∞‡®æ‡®ú‡®∏‡©ç‡®•‡®æ‡®®")
#         y = UnicodeIndicTransliterator.transliterate("‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω ‡∂Ö‡∂ö‡∑ä‡∑Ç‡∂ª ‡∂∏‡∑è‡∂Ω‡∑è‡∑Ä", "si", "hi")
#         self.assertEqual(y, "‡§∏‡§ø‡§Ç‡§π‡§≤ ‡§Ö‡§ï‡•ç‡§∑‡§∞ ‡§Æ‡§æ‡§≤‡§æ‡§µ")
#         z = UnicodeIndicTransliterator.transliterate("‡§∏‡§ø‡§Ç‡§π‡§≤ ‡§Ö‡§ï‡•ç‡§∑‡§∞ ‡§Æ‡§æ‡§≤‡§æ‡§µ", "hi", "si")
#         self.assertEqual(z, "‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω ‡∂Ö‡∂ö‡∑ä‡∑Ç‡∂ª ‡∂∏‡∑è‡∂Ω‡∑è‡∑Ä")
#         t = UnicodeIndicTransliterator.transliterate("‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç ‡ÆÖ‡Æ∞‡Æø‡Æö‡Øç‡Æö‡ØÅ‡Æµ‡Æü‡Æø", "ta", "hi")
#         self.assertEqual(t, "‡§§‡§Æ‡§ø‡§¥‡•ç ‡§Ö‡§∞‡§ø‡§ö‡•ç‡§ö‡•Å‡§µ‡§ü‡§ø")
#         h = UnicodeIndicTransliterator.transliterate("‡§§‡§Æ‡§ø‡§¥‡•ç ‡§Ö‡§∞‡§ø‡§ö‡•ç‡§ö‡•Å‡§µ‡§ü‡§ø", "hi", "ta")
#         self.assertEqual(h, "‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç ‡ÆÖ‡Æ∞‡Æø‡Æö‡Øç‡Æö‡ØÅ‡Æµ‡Æü‡Æø")
#
#     def test_Romanization(self):
#         x = ItransTransliterator.to_itrans("‡§∞‡§æ‡§ú‡§∏‡•ç‡§•‡§æ‡§®", "hi")
#         self.assertTrue(x == "rAjasthAna" or x == "raajasthaana")
#         x = ItransTransliterator.to_itrans("‡§∞‡§æ‡§ú‡§∏‡•ç‡§•‡§æ‡§®", "asdasd")
#         self.assertEqual(x, "‡§∞‡§æ‡§ú‡§∏‡•ç‡§•‡§æ‡§®")
#         ml = ItransTransliterator.to_itrans("‡¥Æ‡¥≤", "ml")
#         self.assertEqual(ml, "mala")
#
#     def test_SinhalaDevanagariTransliterator(self):
#         sin = sdt.devanagari_to_sinhala("‡§∞‡§æ‡§ú‡§∏‡•ç‡§•‡§æ‡§®")
#         self.assertEqual(sin, "‡∂ª‡∑è‡∂¢‡∑É‡∑ä‡∂Æ‡∑è‡∂±")
#         dev = sdt.sinhala_to_devanagari("‡∂ª‡∑è‡∂¢‡∑É‡∑ä‡∂Æ‡∑è‡∂±")
#         self.assertEqual(dev, "‡§∞‡§æ‡§ú‡§∏‡•ç‡§•‡§æ‡§®")
#
#
# class TestScriptInformation(unittest.TestCase):
#     def test_IsVowel(self):
#         self.assertFalse(is_vowel("‡§ï", "hi"))
#         self.assertTrue(is_vowel("‡§Ö", "hi"))
#
#     def test_IsConsonant(self):
#         self.assertTrue(is_consonant("‡§ï", "hi"))
#         self.assertFalse(is_consonant("‡§Ö", "hi"))
#
#     def test_IsVelar(self):
#         self.assertTrue(is_velar("‡§ï", "hi"))
#         self.assertFalse(is_velar("‡§Ö", "hi"))
#
#     def test_IsPalatal(self):
#         self.assertTrue(is_palatal("‡§ö", "hi"))
#         self.assertFalse(is_palatal("‡§§", "hi"))
#
#     def test_IsAspirated(self):
#         self.assertTrue(is_aspirated("‡§õ", "hi"))
#         self.assertFalse(is_aspirated("‡§ï", "hi"))
#
#     def test_IsUnvoiced(self):
#         self.assertTrue(is_unvoiced("‡§ü", "hi"))
#         self.assertFalse(is_unvoiced("‡§ó", "hi"))
#
#     def test_IsNasal(self):
#         self.assertTrue(is_nasal("‡§£", "hi"))
#         self.assertFalse(is_nasal("‡§°", "hi"))
#
#     def test_IsVowelSign(self):
#         self.assertTrue(is_vowel_sign("‡§æ", "hi"))
#
#     def test_IsNukta(self):
#         self.assertTrue(is_nukta("‡§º", "hi"))
#
#     def test_IsAum(self):
#         self.assertTrue(is_aum("‡•ê", "hi"))
#
#     def test_IsHalanta(self):
#         self.assertTrue(is_halanta("‡•ç", "hi"))
#
#     def test_IsRetroflex(self):
#         self.assertTrue(is_retroflex("‡§ü", "hi"))
#
#     def test_IsDental(self):
#         self.assertTrue(is_dental("‡§§", "hi"))
#
#     def test_IsLabial(self):
#         self.assertTrue(is_labial("‡§™", "hi"))
#
#     def test_IsVoiced(self):
#         self.assertTrue(is_voiced("‡§ó", "hi"))
#
#     def test_IsUnAspirated(self):
#         self.assertTrue(is_unaspirated("‡§ú", "hi"))
#
#     def test_IsFricative(self):
#         self.assertTrue(is_fricative("‡§∂", "hi"))
#
#     def test_IsApproximant(self):
#         self.assertTrue(is_approximant("‡§Ø", "hi"))
#
#     def test_IsNumber(self):
#         self.assertTrue(is_number("‡•®", "hi"))
#
#     def test_offset_to_char(self):
#         self.assertEqual(offset_to_char(0x021, "hi"), "‡§°")
#
#     def test_in_coordinated_range(self):
#         self.assertTrue(in_coordinated_range(0x6E))
#
#     def test_is_indiclang_char(self):
#         self.assertTrue(is_indiclang_char("‡§ï", "hi"))
#
#     def test_swadesh_greek(self):
#         swadesh = Swadesh("gr")
#         first_word = "·ºêŒ≥œé"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_latin(self):
#         swadesh = Swadesh("la")
#         first_word = "ego"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_tocharianB(self):
#         swadesh = Swadesh("txb")
#         first_word = "√±√§≈õ"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_old_portuguese(self):
#         swadesh = Swadesh("pt_old")
#         first_word = "eu"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_sanskrit(self):
#         swadesh = Swadesh("sa")
#         first_word = "‡§Ö‡§π‡§Æ‡•ç"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_hindi(self):
#         swadesh = Swadesh("hi")
#         first_word = "‡§Æ‡•à‡§Ç"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_old_english(self):
#         swadesh = Swadesh("eng_old")
#         first_word = "ic, iƒãƒã, ih"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_old_norse(self):
#         swadesh = Swadesh("old_norse")
#         first_word = "ek"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#     def test_swadesh_arabic(self):
#         swadesh = Swadesh("ar")
#         first_word = "ÿ£ŸÜÿß"
#         match = swadesh.words()[0]
#         self.assertEqual(first_word, match)
#
#
# class TestRunes(unittest.TestCase):
#     def test_rune_alphabet_name(self):
#         self.assertEqual(runes.RunicAlphabetName.elder_futhark.value, "elder_futhark")
#
#     def test_rune_definition(self):
#         haglaz = runes.Rune(
#             runes.RunicAlphabetName.elder_futhark, "\u16BA", "h", "h", "haglaz"
#         )
#         self.assertEqual(haglaz.form, "·ö∫")
#
#     def test_runic_transcription_definition(self):
#         inscription = "·ö¶·õÅ·õÖ·ö¥·öæ·õ´·õÖ·ö¢·ö¥·õ´·ö¥·ö¢·öæ·õÖ·ö±·õ´·ö±·õÖ·õÅ·õã·õè·ö¢·õ´·õã·õè·õÖ·õÅ·öæ·õÖ ·õÖ·ö†·õè·õÅ·õ¶·õ´·ö¢·õÖ·ö±·õ´·õí·ö±·ö¢·ö¶·ö¢·ö±·õ´·õã·õÅ·öæ"
#         transcription = runes.Transcriber.transcribe(inscription, runes.YOUNGER_FUTHARK)
#         self.assertEqual(
#             transcription, "√æiakn·õ´auk·õ´kunar·õ´raistu·õ´staina·õ´aftiR·õ´uar·õ´bru√æur·õ´sin"
#         )


if __name__ == "__main__":
    unittest.main()
